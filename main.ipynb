{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from numpy import isnan\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from keras.utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress\n",
    "from FS.ssa import jfs as jfs_1\n",
    "from FS.hho import jfs as jfs_2\n",
    "from FS.HHO_SSA_Hyb import jfs as jfs_3\n",
    "from FS.ga import jfs as jfs_0\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, Flatten\n",
    "from keras.layers import LSTM, SimpleRNN, GRU, Bidirectional, BatchNormalization,Convolution1D,MaxPooling1D, Reshape, GlobalAveragePooling1D\n",
    "from keras.utils import to_categorical\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import tensorflow as tf\n",
    "from scipy.stats import kurtosis,skew\n",
    "import smote_variants as sv\n",
    "from Sub_functions import Main_perf_val_acc_sen_spe_1_prc, Main_perf_val_acc_sen_spe_1,Main_perf_val_acc_sen_spe_2, \\\n",
    "                        Main_perf_val_acc_sen_spe_3, Main_perf_val_acc_sen_spe_4, ext_main_prc\n",
    "# from sklearn.externals import joblib\n",
    "from sklearn import svm\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "from pycm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_lab_change(tem_feat,Str_lab):\n",
    "    tem_feat = np.delete(tem_feat, (6), axis=1)#Eliminate Timestamp attributes\n",
    "    tem_feat = np.delete(tem_feat, (0), axis=1)#Eliminate IP  attributes\n",
    "    fin_feat = tem_feat\n",
    "    tem_lab=tem_feat[:,-1]\n",
    "    for t in range(0, len(tem_lab)):\n",
    "        fin_feat[t, 0] =int(ipaddress.ip_address(fin_feat[t, 0]))\n",
    "        fin_feat[t, 2] =int(ipaddress.ip_address(fin_feat[t, 2]))\n",
    "        curr_lab = tem_lab[t]\n",
    "        if curr_lab == Str_lab[0]:\n",
    "            fin_feat[t, -1] = 0\n",
    "            fin_feat[t, -2] = 0\n",
    "        elif curr_lab == Str_lab[1]:\n",
    "            fin_feat[t, -1] = 0\n",
    "            fin_feat[t, -2] = 0\n",
    "        elif curr_lab == Str_lab[2]:\n",
    "            fin_feat[t, -1] = 1\n",
    "            fin_feat[t, -2] = 1\n",
    "        elif curr_lab == Str_lab[3]:\n",
    "            fin_feat[t, -1] = 2\n",
    "            fin_feat[t, -2] = 2\n",
    "        elif curr_lab == Str_lab[4]:\n",
    "            fin_feat[t, -1] = 3\n",
    "            fin_feat[t, -2] = 3\n",
    "        else:\n",
    "            fin_feat[t, -1] = 4\n",
    "            fin_feat[t, -2] = 4\n",
    "    return fin_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,target_names,title='Confusion matrix',cmap=None,normalize=True):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]), horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]), horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_data_splitup(Sel_identifier_3,Final_Feat,Final_Lab,tr_per):\n",
    "    tot_attacks = np.unique(Final_Lab)\n",
    "    tr_data, tst_data, tr_lab, tst_lab = [], [], [], []\n",
    "    for y in range(0, len(tot_attacks)):\n",
    "        ind_1 = np.where(Final_Lab == y)[0]\n",
    "        # try:\n",
    "        #      ind_1=ind_1[:300,]\n",
    "        # except:\n",
    "        #     ind_1=ind_1\n",
    "        tr_upto = int(np.round(tr_per * len(ind_1)))\n",
    "        if y > 0:\n",
    "            tr_data = np.vstack((tr_data, Final_Feat[ind_1[:tr_upto], :]))\n",
    "            tst_data = np.vstack((tst_data, Final_Feat[ind_1[tr_upto:],:]))\n",
    "            tr_lab = np.hstack((tr_lab, Final_Lab[ind_1[:tr_upto],]))\n",
    "            tst_lab = np.hstack((tst_lab, Final_Lab[ind_1[tr_upto:],]))\n",
    "        else:\n",
    "            tr_data = (Final_Feat[ind_1[:tr_upto], :])\n",
    "            tst_data = (Final_Feat[ind_1[tr_upto:], :])\n",
    "            tr_lab = (Final_Lab[ind_1[:tr_upto],])\n",
    "            tst_lab = (Final_Lab[ind_1[tr_upto:],])\n",
    "        # tr_data=np.asarray(tr_data)\n",
    "        print(len(ind_1))\n",
    "    # tr_data = tr_data[:, Sel_identifier_3]\n",
    "    # tst_data = tst_data[:, Sel_identifier_3]\n",
    "    return tr_data,tr_lab,tst_data,tst_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_data_splitup_tem(tot_attacks,Final_Feat,Final_Lab,tr_per):\n",
    "    tr_data, tst_data, tr_lab, tst_lab = [], [], [], []\n",
    "    for y in range(0, len(tot_attacks)):\n",
    "        ind_1 = np.where(Final_Lab == y)[0]\n",
    "        try:\n",
    "             ind_1=ind_1[:5000,]\n",
    "        except:\n",
    "            ind_1=ind_1\n",
    "        tr_upto = int(np.round(tr_per * len(ind_1)))\n",
    "        if y > 0:\n",
    "            tr_data = np.vstack((tr_data, Final_Feat[ind_1[:tr_upto], :]))\n",
    "            tst_data = np.vstack((tst_data, Final_Feat[ind_1[tr_upto:], :]))\n",
    "            tr_lab = np.hstack((tr_lab, Final_Lab[ind_1[:tr_upto],]))\n",
    "            tst_lab = np.hstack((tst_lab, Final_Lab[ind_1[tr_upto:],]))\n",
    "        else:\n",
    "            tr_data = (Final_Feat[ind_1[:tr_upto], :])\n",
    "            tst_data = (Final_Feat[ind_1[tr_upto:], :])\n",
    "            tr_lab = (Final_Lab[ind_1[:tr_upto],])\n",
    "            tst_lab = (Final_Lab[ind_1[tr_upto:],])\n",
    "        # tr_data=np.asarray(tr_data)\n",
    "        print(len(ind_1))\n",
    "    return tr_data,tr_lab,tst_data,tst_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_CNN_LSTM_Classifier_ROC_AUC(tr_data,tr_lab,tst_data,ep):\n",
    "    tr_data = np.reshape(tr_data, (tr_data.shape[0], tr_data.shape[1], 1))\n",
    "    tst_data = np.reshape(tst_data, (tst_data.shape[0], tst_data.shape[1], 1))\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "    ###############################################\n",
    "    batch_size = 128\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(64, kernel_size=64, border_mode=\"same\", activation=\"relu\", input_shape=(tr_data.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_length=(10)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_length=(5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    # model.add(Reshape((128, 1), input_shape = (128, )))\n",
    "    model.add(Dropout(0.06))\n",
    "    model.add(Dense(tr_lab.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    for layer in model.layers:\n",
    "        print(layer.output_shape)\n",
    "    model.summary()\n",
    "    model.fit(tr_data, tr_lab, validation_data=(tr_data, tr_lab), epochs=ep)\n",
    "\n",
    "    pred = model.predict(tst_data)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    # y_eval = np.argmax(tst_lab, axis=1)\n",
    "    return pred,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_CNN_LSTM_Classifier(tr_data,tr_lab,tst_data,ep):\n",
    "    tr_data = np.reshape(tr_data, (tr_data.shape[0], tr_data.shape[1], 1))\n",
    "    tst_data = np.reshape(tst_data, (tst_data.shape[0], tst_data.shape[1], 1))\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "    ###############################################\n",
    "    batch_size = 128\n",
    "    model = Sequential()\n",
    "    model.add(Convolution1D(64, kernel_size=64, border_mode=\"same\", activation=\"relu\", input_shape=(tr_data.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_length=(10)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=False)))\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_length=(5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    # model.add(Reshape((128, 1), input_shape = (128, )))\n",
    "    model.add(Dropout(0.06))\n",
    "    model.add(Dense(tr_lab.shape[1]))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    for layer in model.layers:\n",
    "        print(layer.output_shape)\n",
    "    model.summary()\n",
    "    model.fit(tr_data, tr_lab, validation_data=(tr_data, tr_lab), epochs=ep)\n",
    "\n",
    "    pred = model.predict(tst_data)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    # y_eval = np.argmax(tst_lab, axis=1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_AdaBoost_Classifier(tr_data, tr_lab,tst_data):\n",
    "    clf = AdaBoostClassifier(random_state=3)\n",
    "    clf.fit(tr_data, tr_lab)\n",
    "    pred_lab = clf.predict(tst_data)\n",
    "    return pred_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_AdaBoost_Classifier_ROC_AUC(tr_data, tr_lab,tst_data):\n",
    "    clf = AdaBoostClassifier(random_state=3)\n",
    "    clf.fit(tr_data, tr_lab)\n",
    "    pred_lab = clf.predict(tst_data)\n",
    "    return pred_lab,clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_BiLSTM_Classifier_ROC_AUC(tr_data,tr_lab,tst_data,ep):\n",
    "    tr_data=tf.keras.utils.normalize(tr_data)\n",
    "    tst_data=tf.keras.utils.normalize(tst_data)\n",
    "\n",
    "    tr_data = np.reshape(tr_data, (tr_data.shape[0], tr_data.shape[1], 1))\n",
    "    tst_data = np.reshape(tst_data, (tst_data.shape[0], tst_data.shape[1], 1))\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(tr_data.shape[1],1)))\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_length=(5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    model.add(Dropout(0.06))\n",
    "\n",
    "    model.add(Dense(tr_lab.shape[1]))\n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    # checkpoint\n",
    "    filepath = \"weights_BiLstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    history = model.fit(tr_data,tr_lab, epochs=ep, batch_size=64, callbacks=callbacks_list, verbose=1)\n",
    "    filename = \"BiLSTM_model.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    loaded_model = joblib.load(filename)\n",
    "    # y_pred_1 = np.round(history.model.predict(tst_data))\n",
    "    pred = model.predict(tst_data)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    return pred,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_SAE_LSTM(tr_data,tr_lab,tst_data,ep):\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input\n",
    "    from tensorflow.keras.layers import Dense\n",
    "    from tensorflow.keras.layers import LeakyReLU\n",
    "    from tensorflow.keras.layers import BatchNormalization\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    tr_data=tf.keras.utils.normalize(tr_data)\n",
    "    tst_data=tf.keras.utils.normalize(tst_data)\n",
    "    # scale data\n",
    "    t = MinMaxScaler()\n",
    "    t.fit(tr_data)\n",
    "    tr_data = t.transform(tr_data)\n",
    "    tst_data = t.transform(tst_data)\n",
    "    # number of input columns\n",
    "    n_inputs = tr_data.shape[1]\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "\n",
    "    # split into train test sets\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "    # define encoder\n",
    "    visible = Input(shape=(n_inputs,))\n",
    "    # encoder level 1\n",
    "    e = Dense(n_inputs * 2)(visible)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "    # encoder level 2\n",
    "    e = Dense(n_inputs)(e)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = LeakyReLU()(e)\n",
    "    # bottleneck\n",
    "    n_bottleneck = n_inputs\n",
    "    bottleneck = Dense(n_bottleneck)(e)\n",
    "    # define decoder, level 1\n",
    "    d = Dense(n_inputs)(bottleneck)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "    # decoder level 2\n",
    "    d = Dense(n_inputs * 2)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU()(d)\n",
    "    # output layer\n",
    "    output = Dense(tr_lab.shape[1], activation='linear')(d)\n",
    "    # define autoencoder model\n",
    "    model = Model(inputs=visible, outputs=output)\n",
    "    # compile autoencoder model\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # plot the autoencoder\n",
    "    # plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\n",
    "    # fit the autoencoder model to reconstruct input\n",
    "    history = model.fit(tr_data,tr_lab, epochs=ep, batch_size=16, verbose=2, validation_data=(tr_data,tr_lab))\n",
    "    pred = model.predict(tst_data)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    return pred,model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_BiLSTM_Classifier(tr_data,tr_lab,tst_data,ep):\n",
    "    tr_data=tf.keras.utils.normalize(tr_data)\n",
    "    tst_data=tf.keras.utils.normalize(tst_data)\n",
    "\n",
    "    tr_data = np.reshape(tr_data, (tr_data.shape[0], tr_data.shape[1], 1))\n",
    "    tst_data = np.reshape(tst_data, (tst_data.shape[0], tst_data.shape[1], 1))\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(tr_data.shape[1],1)))\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_length=(5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    model.add(Dropout(0.06))\n",
    "\n",
    "    model.add(Dense(tr_lab.shape[1]))\n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    # checkpoint\n",
    "    filepath = \"weights_BiLstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    history = model.fit(tr_data,tr_lab, epochs=ep, batch_size=64, callbacks=callbacks_list, verbose=1)\n",
    "    filename = \"BiLSTM_model.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    loaded_model = joblib.load(filename)\n",
    "    # y_pred_1 = np.round(history.model.predict(tst_data))\n",
    "    pred = model.predict(tst_data)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_LightGBM_Classifier(tr_data, tr_lab,tst_data):\n",
    "    # build the lightgbm model\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    clf.fit(tr_data, tr_lab)\n",
    "    pred_lab = clf.predict(tst_data)\n",
    "    return pred_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_LightGBM_Classifier_ROC_AUC(tr_data, tr_lab,tst_data):\n",
    "    # build the lightgbm model\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    clf.fit(tr_data, tr_lab)\n",
    "    pred_lab = clf.predict(tst_data)\n",
    "    return pred_lab,clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mealpy.swarm_based import HHO,SSA,PSO\n",
    "def fitness_function1(solution,model,tst_data,tst_lab):\n",
    "    d1=int(solution.shape[0]/5)\n",
    "    d2=5\n",
    "    tem_sol=np.reshape(solution, (d1, d2))\n",
    "    wei_to_train=model.layers[6].get_weights()\n",
    "    wei_to_train[0]=tem_sol\n",
    "    model.layers[6].set_weights(wei_to_train)\n",
    "    pred = model.predict(tst_data)\n",
    "    pred_1 = np.argmax(pred, axis=1)\n",
    "    # from sklearn.metrics import classification_report as cr\n",
    "    # per=cr(tst_lab,pred_1)\n",
    "    acc=np.sum(tst_lab==pred_1)/len(pred_1)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function_Data_Balancing(solution,Final_Feat, Final_Lab):\n",
    "    tr_per = 0.75\n",
    "    tr_data, tr_lab, tst_data, tst_lab = main_data_splitup_tem(Final_Feat, Final_Lab, tr_per)\n",
    "    pred_1 = main_KNN_Classifier(tr_data, tr_lab, tst_data)\n",
    "    acc = np.sum(tst_lab == pred_1) / len(pred_1)\n",
    "    # d1=int(solution.shape[0]/5)\n",
    "    # d2=5\n",
    "    # tem_sol=np.reshape(solution, (d1, d2))\n",
    "    # wei_to_train=model.layers[6].get_weights()\n",
    "    # wei_to_train[0]=tem_sol\n",
    "    # model.layers[6].set_weights(wei_to_train)\n",
    "    # pred = model.predict(tst_data)\n",
    "    # pred_1 = np.argmax(pred, axis=1)\n",
    "    # # from sklearn.metrics import classification_report as cr\n",
    "    # # per=cr(tst_lab,pred_1)\n",
    "    # acc=np.sum(tst_lab==pred_1)/len(pred_1)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_final_data_bal_out(Final_Feat, Final_Lab,best_position2):\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    Final_Feat, Final_Lab = oversample.fit_resample(Final_Feat, Final_Lab)\n",
    "    # Final_Feat, Final_Lab = oversample.fit_resample(Final_Feat, Final_Lab)\n",
    "    # Final_Feat, Final_Lab = oversample.fit_resample(Final_Feat, Final_Lab)\n",
    "    # Final_Feat, Final_Lab = oversample.fit_resample(Final_Feat, Final_Lab)\n",
    "    return Final_Feat, Final_Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_Data_Balancing_optimization(ii,Final_Feat, Final_Lab):\n",
    "\n",
    "    if ii == 0:\n",
    "        X_samp=Final_Feat\n",
    "        y_samp=Final_Lab\n",
    "    elif ii==1:\n",
    "        X_samp, y_samp = main_final_data_bal_out(Final_Feat, Final_Lab, Final_Lab)\n",
    "    elif ii==2:\n",
    "        oversampler= sv.SMOTE_PSO(k=3,nn_params={},eps=0.05,n_pop=2,w=1.0,c1=2.0, c2=2.0, num_it=1,n_jobs=1,random_state=None)\n",
    "        X_samp, y_samp = oversampler.sample(Final_Feat, Final_Lab)\n",
    "    elif ii==3:\n",
    "        oversampler= sv.GASMOTE(n_neighbors=2,nn_params={}, maxn=7, n_pop=5,popl3=5,pm=0.3,pr=0.2,Ge=2,n_jobs=1,random_state=None)\n",
    "        X_samp, y_samp = oversampler.sample(Final_Feat, Final_Lab)\n",
    "    elif ii==4:\n",
    "        oversampler = sv.SSO(proportion=1.0,h=10, k=5,nn_params={},alpha=0.5,n_jobs=1,random_state=None)\n",
    "        X_samp, y_samp = oversampler.sample(Final_Feat, Final_Lab)\n",
    "    elif ii == 5:\n",
    "        oversampler = sv.HHO(proportion=1.0,K2=5,K1_frac=0.5,nn_params={},n_jobs=1,random_state=None)\n",
    "        X_samp, y_samp = oversampler.sample(Final_Feat, Final_Lab)\n",
    "    else:\n",
    "        oversampler = sv.HHO_SSA_Mod_SMOTE(n_neighbors=2, nn_params={}, maxn=7, n_pop=5, popl3=5, pm=0.3, pr=0.2, Ge=2,n_jobs=1, random_state=None)\n",
    "        X_samp, y_samp = oversampler.sample(Final_Feat, Final_Lab)\n",
    "\n",
    "    return X_samp, y_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_weight_updation_optimization(ii,curr_wei,model,tst_data,tst_lab):\n",
    "    problem_dict1 = {\n",
    "        \"fit_func\": fitness_function1,\n",
    "        \"lb\": [curr_wei.min(), ] * curr_wei.shape[0]*curr_wei.shape[1],\n",
    "        \"ub\": [curr_wei.max(), ] * curr_wei.shape[0]*curr_wei.shape[1],\n",
    "        \"minmax\": \"min\",\n",
    "        \"log_to\": None,\n",
    "        \"save_population\": False,\n",
    "        \"Curr_Weight\":curr_wei,\n",
    "        \"Model_trained_Partial\":model,\n",
    "        \"tst_data\": tst_data,\n",
    "        \"tst_lab\": tst_lab,\n",
    "    }\n",
    "    if ii==0:\n",
    "        model = PSO.BasePSO(problem_dict1, epoch=5, pop_size=10, pr=0.03)\n",
    "    elif ii==1:\n",
    "        model = HHO.BaseHHO(problem_dict1, epoch=5, pop_size=10, pr=0.03)\n",
    "    elif ii==2:\n",
    "        model = SSA.BaseSSA(problem_dict1, epoch=5, pop_size=10, pr=0.03)\n",
    "    else:\n",
    "        model = HHO.BaseHHO_SSA_Pro(problem_dict1, epoch=5, pop_size=10, pr=0.03)\n",
    "    best_position2, best_fitness2 = curr_wei,model.solve()\n",
    "    Glob_best_fit_2=model.history.list_global_best_fit\n",
    "    return best_position2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_BiLSTM_LiGBM_Classifier_ROC_AUC(tr_data,tr_lab,tst_data,tst_lab,ii,ep):\n",
    "    tr_data_org=tf.keras.utils.normalize(tr_data)\n",
    "    tst_data_org=tf.keras.utils.normalize(tst_data)\n",
    "    tr_lab_org=tr_lab\n",
    "    tr_data = np.reshape(tr_data_org, (tr_data_org.shape[0], tr_data_org.shape[1], 1))\n",
    "    tst_data = np.reshape(tst_data_org, (tst_data_org.shape[0], tst_data_org.shape[1], 1))\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(tr_data.shape[1],1)))\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_length=(5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    model.add(Dropout(0.06))\n",
    "    model.add(Dense(tr_lab.shape[1]))\n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    # checkpoint\n",
    "    filepath = \"weights_BiLstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    history = model.fit(tr_data,tr_lab, epochs=ep, batch_size=640, callbacks=callbacks_list, verbose=1)\n",
    "    wei_to_train=model.layers[6].get_weights()\n",
    "    wei_to_train_1=wei_to_train[0]\n",
    "    wei_to_train_2=wei_to_train[1]\n",
    "    ###########   Weight Modification    #########################\n",
    "    wei_to_train_1=main_weight_updation_optimization(ii, wei_to_train_1,model,tst_data,tst_lab)\n",
    "    wei_to_train[0]=np.reshape(wei_to_train_1,(int(wei_to_train[0].shape[0]),int(wei_to_train[0].shape[1])))\n",
    "    model.layers[6].set_weights(wei_to_train)\n",
    "    ###################################################\n",
    "    filename = \"BiLSTM_model.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    model = joblib.load(filename)\n",
    "    # y_pred_1 = np.round(history.model.predict(tst_data))\n",
    "    pred = model.predict(tst_data)\n",
    "    pred_1 = np.argmax(pred, axis=1)\n",
    "    return pred_1,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_BiLSTM_LiGBM_Classifier(tr_data,tr_lab,tst_data,tst_lab,ii,ep):\n",
    "    tr_data_org=tf.keras.utils.normalize(tr_data)\n",
    "    tst_data_org=tf.keras.utils.normalize(tst_data)\n",
    "    tr_lab_org=tr_lab\n",
    "    tr_data = np.reshape(tr_data_org, (tr_data_org.shape[0], tr_data_org.shape[1], 1))\n",
    "    tst_data = np.reshape(tst_data_org, (tst_data_org.shape[0], tst_data_org.shape[1], 1))\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(tr_data.shape[1],1)))\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_length=(5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    model.add(Dropout(0.06))\n",
    "    model.add(Dense(tr_lab.shape[1]))\n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    # checkpoint\n",
    "    filepath = \"weights_BiLstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    history = model.fit(tr_data,tr_lab, epochs=ep, batch_size=640, callbacks=callbacks_list, verbose=1)\n",
    "    wei_to_train=model.layers[6].get_weights()\n",
    "    wei_to_train_1=wei_to_train[0]\n",
    "    wei_to_train_2=wei_to_train[1]\n",
    "    ###########   Weight Modification    #########################\n",
    "    wei_to_train_1=main_weight_updation_optimization(ii, wei_to_train_1,model,tst_data,tst_lab)\n",
    "    wei_to_train[0]=np.reshape(wei_to_train_1,(int(wei_to_train[0].shape[0]),int(wei_to_train[0].shape[1])))\n",
    "    model.layers[6].set_weights(wei_to_train)\n",
    "    ###################################################\n",
    "    filename = \"BiLSTM_model.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    model = joblib.load(filename)\n",
    "    # y_pred_1 = np.round(history.model.predict(tst_data))\n",
    "    pred = model.predict(tst_data)\n",
    "    pred_1 = np.argmax(pred, axis=1)\n",
    "    return pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_BiLSTM_LiGBM_Classifier_Mod_ROC_AUC(tr_data,tr_lab,tst_data,tst_lab,ii,ep):\n",
    "    tr_data_org=tf.keras.utils.normalize(tr_data)\n",
    "    tst_data_org=tf.keras.utils.normalize(tst_data)\n",
    "    tr_lab_org=tr_lab\n",
    "    tr_data = np.reshape(tr_data_org, (tr_data_org.shape[0], tr_data_org.shape[1], 1))\n",
    "    tst_data = np.reshape(tst_data_org, (tst_data_org.shape[0], tst_data_org.shape[1], 1))\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(tr_data.shape[1],1)))\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_length=(5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    model.add(Dropout(0.06))\n",
    "    model.add(Dense(tr_lab.shape[1]))\n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    #Create Flow Chart\n",
    "    plot_model(model, to_file='model_flowchart.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # checkpoint\n",
    "    filepath = \"weights_BiLstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    history = model.fit(tr_data,tr_lab, epochs=ep, batch_size=640, callbacks=callbacks_list, verbose=1)\n",
    "    wei_to_train=model.layers[6].get_weights()\n",
    "    wei_to_train_1=wei_to_train[0]\n",
    "    wei_to_train_2=wei_to_train[1]\n",
    "    wei_to_train_1=main_weight_updation_optimization(ii, wei_to_train_1,model,tst_data,tst_lab)\n",
    "    wei_to_train[0]=np.reshape(wei_to_train_1,(int(wei_to_train[0].shape[0]),int(wei_to_train[0].shape[1])))\n",
    "    model.layers[6].set_weights(wei_to_train)\n",
    "    filename = \"BiLSTM_model.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    model = joblib.load(filename)\n",
    "    # y_pred_1 = np.round(history.model.predict(tst_data))\n",
    "    pred = model.predict(tst_data)\n",
    "    pred_1 = np.argmax(pred, axis=1)\n",
    "\n",
    "    ###################################\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    clf.fit(tr_data_org, tr_lab_org)\n",
    "    pred_2 = clf.predict(tst_data_org)\n",
    "    DD=pred_1.astype(np.int32)+pred_2.astype(np.int32)\n",
    "    pred=np.round((0.05*pred_1.astype(np.int32)+0.95*pred_2.astype(np.int32)))\n",
    "    pred=pred.astype(int)\n",
    "    return pred,clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_BiLSTM_LiGBM_Classifier_Mod(tr_data,tr_lab,tst_data,tst_lab,ii,ep):\n",
    "    tr_data_org=tf.keras.utils.normalize(tr_data)\n",
    "    tst_data_org=tf.keras.utils.normalize(tst_data)\n",
    "    tr_lab_org=tr_lab\n",
    "    tr_data = np.reshape(tr_data_org, (tr_data_org.shape[0], tr_data_org.shape[1], 1))\n",
    "    tst_data = np.reshape(tst_data_org, (tst_data_org.shape[0], tst_data_org.shape[1], 1))\n",
    "    tr_lab = to_categorical(tr_lab)\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(tr_data.shape[1],1)))\n",
    "    model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "    model.add(MaxPooling1D(pool_length=(5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "    model.add(Dropout(0.06))\n",
    "    model.add(Dense(tr_lab.shape[1]))\n",
    "    model.compile(optimizer='sgd', loss='mse')\n",
    "    # checkpoint\n",
    "    filepath = \"weights_BiLstm.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "    history = model.fit(tr_data,tr_lab, epochs=ep, batch_size=640, callbacks=callbacks_list, verbose=1)\n",
    "    wei_to_train=model.layers[6].get_weights()\n",
    "    wei_to_train_1=wei_to_train[0]\n",
    "    wei_to_train_2=wei_to_train[1]\n",
    "    wei_to_train_1=main_weight_updation_optimization(ii, wei_to_train_1,model,tst_data,tst_lab)\n",
    "    wei_to_train[0]=np.reshape(wei_to_train_1,(int(wei_to_train[0].shape[0]),int(wei_to_train[0].shape[1])))\n",
    "    model.layers[6].set_weights(wei_to_train)\n",
    "    filename = \"BiLSTM_model.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    model = joblib.load(filename)\n",
    "    # y_pred_1 = np.round(history.model.predict(tst_data))\n",
    "    pred = model.predict(tst_data)\n",
    "    pred_1 = np.argmax(pred, axis=1)\n",
    "\n",
    "    ###################################\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    clf.fit(tr_data_org, tr_lab_org)\n",
    "    pred_2 = clf.predict(tst_data_org)\n",
    "    DD=pred_1.astype(np.int32)+pred_2.astype(np.int32)\n",
    "    pred=np.round((0.05*pred_1.astype(np.int32)+0.95*pred_2.astype(np.int32)))\n",
    "    pred=pred.astype(int)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_KNN_Classifier(tr_data, tr_lab,tst_data):\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    knn.fit(tr_data, tr_lab)\n",
    "    pred_lab = knn.predict(tst_data)\n",
    "    return pred_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_SVM_Classifier(tr_data, tr_lab,tst_data):\n",
    "    # Create a svm Classifier\n",
    "    clf=KNeighborsClassifier(n_neighbors=2)\n",
    "    # clf = svm.SVC(kernel='linear')  # Linear Kernel\n",
    "    clf.fit(tr_data, tr_lab)\n",
    "    pred_lab = clf.predict(tst_data)\n",
    "    return pred_lab,clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_KNN_Classifier_ROC_AUC(tr_data, tr_lab,tst_data):\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    knn.fit(tr_data, tr_lab)\n",
    "    pred_lab = knn.predict(tst_data)\n",
    "    return pred_lab,knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_Important_Identifier_Detection(tr_data,tr_lab,tst_data,tst_lab,pl,jfs):\n",
    "    fold = {'xt': tst_data, 'yt': tst_lab, 'xv': tst_data, 'yv': tst_lab}\n",
    "    # parameter\n",
    "    k = 2  # k-value in KNN\n",
    "    N = 5  # number of particles\n",
    "    T = 2  # maximum number of iterations\n",
    "    opts = {'k': k, 'fold': fold, 'N': N, 'T': T}\n",
    "    # perform Important Identified Detection\n",
    "    fmdl = jfs(tst_data, tst_lab, opts)\n",
    "    sf = fmdl['sf']\n",
    "    tr_data = tr_data[:, sf]\n",
    "    tst_data = tst_data[:, sf]\n",
    "    if pl==1:\n",
    "        # plot convergence\n",
    "        curve = fmdl['c']\n",
    "        curve = curve.reshape(np.size(curve, 1))\n",
    "        x = np.arange(0, opts['T'], 1.0) + 1.0\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(x, curve, 'o-')\n",
    "        ax.set_xlabel('Number of Iterations')\n",
    "        ax.set_ylabel('Fitness')\n",
    "        ax.set_title('Convergence')\n",
    "        ax.grid()\n",
    "        plt.show()\n",
    "    return sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_feature_combine(Final_Feat):\n",
    "    time_win = 2\n",
    "    feat_tem = []\n",
    "    for ii in range(0, len(Final_Feat)):\n",
    "        if ii == 0:\n",
    "            curr_data = Final_Feat[ii, :]\n",
    "        else:\n",
    "            curr_data = Final_Feat[ii, :]\n",
    "            # curr_data = Final_Feat[ii-1:ii, :]\n",
    "\n",
    "        F1 = kurtosis(curr_data, axis=0, bias=True)\n",
    "        F2 = skew(curr_data, axis=0, bias=True)\n",
    "        F3 = np.mean(curr_data)\n",
    "        F4 = np.var(curr_data)\n",
    "        feat_tem.append(np.hstack((F1, F2, F3, F4)))\n",
    "    feat_tem_1 = np.asarray(feat_tem)\n",
    "    Final_Feat = np.hstack((Final_Feat, feat_tem_1))\n",
    "    return Final_Feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_evalution_CM(y, y_pred):\n",
    "    # confusion = confusion_matrix(y, y_pred)\n",
    "    # tp, fp, fn, tn = confusion.flatten()\n",
    "    cm1 = ConfusionMatrix(actual_vector=y, predict_vector=y_pred)\n",
    "    A=cm1.TP\n",
    "    new_lis = np.array(list(A.items()))\n",
    "    TP = np.sum(new_lis)\n",
    "    A=cm1.TN\n",
    "    new_lis = np.array(list(A.items()))\n",
    "    TN = np.sum(new_lis)\n",
    "    A=cm1.FP\n",
    "    new_lis = np.array(list(A.items()))\n",
    "    FP = np.sum(new_lis)\n",
    "    A=cm1.FN\n",
    "    new_lis = np.array(list(A.items()))\n",
    "    FN = np.sum(new_lis)\n",
    "    SEN = (TP) / (TP + FN)\n",
    "    SPE = (TN) / (TN + FP)\n",
    "    ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "    FMS = (2 * TP) / (2 * TP + FP + FN)\n",
    "    PRE = (TP) / (TP + FP)\n",
    "    REC = SEN\n",
    "    TS = (TP) / (TP + FP + FN)  # Threat score\n",
    "    NPV = (TN) / (TN + FN)  # negative predictive value\n",
    "    FOR = (FN) / (FN + TN)  # false omission rate\n",
    "    MCC = matthews_corrcoef(y, y_pred)  # Matthews correlation coefficient\n",
    "    return [ACC, SEN, SPE, PRE, REC, FMS, TS, NPV, FOR, MCC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,tt):\n",
    "    tr_per = 0.4\n",
    "    epoch = 50\n",
    "    perf_A = []\n",
    "    perf_B = []\n",
    "    perf_C = []\n",
    "    perf_D = []\n",
    "    perf_E = []\n",
    "    perf_F = []\n",
    "    perf_G = []\n",
    "    perf_H = []\n",
    "    perf_I = []\n",
    "    perf_J = []\n",
    "    perf_K= []\n",
    "    for a in range(0,3):\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat, Final_Lab, tr_per)\n",
    "        pred_0=main_SVM_Classifier(tr_data, tr_lab, tst_data)######SVM Classifier\n",
    "        pred_1=main_SAE_LSTM(tr_data, tr_lab, tst_data, epoch)######  SAE-LSTM Classifier\n",
    "        pred_2 = main_KNN_Classifier(tr_data, tr_lab, tst_data)######  Knn Classifier\n",
    "        pred_3 = main_CNN_LSTM_Classifier(tr_data, tr_lab, tst_data, epoch)######  CNN-LSTM Classifier\n",
    "        pred_4 = main_LightGBM_Classifier(tr_data, tr_lab, tst_data)######  LightGBM Classifier\n",
    "        pred_5 = main_AdaBoost_Classifier(tr_data, tr_lab, tst_data)######  Adaboost Classifier\n",
    "        pred_6 = main_BiLSTM_Classifier(tr_data, tr_lab, tst_data, epoch)######  BiLSTM Classifier\n",
    "        pred_7 = main_BiLSTM_LiGBM_Classifier(tr_data, tr_lab, tst_data, tst_lab, 0, epoch)######  PSO Tuned BiLSTM Classifier\n",
    "        pred_8 = main_BiLSTM_LiGBM_Classifier(tr_data, tr_lab, tst_data, tst_lab, 1, epoch)######  SSO Tuned BiLSTM Classifier\n",
    "        pred_9 = main_BiLSTM_LiGBM_Classifier(tr_data, tr_lab, tst_data, tst_lab, 2, epoch)######  HHO Tuned BiLSTM Classifier\n",
    "        pred_10 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)######  Proposed Tuned BiLSTM Classifier\n",
    "        ################   Performance Extraction Using Confusion Matrix   ###############\n",
    "        [ACC0, SEN0, SPE0, PRE0, REC0, FMS0, TS0, NPV0, FOR0, MCC0] = perf_evalution_CM(tst_lab, pred_0)\n",
    "        [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1] = perf_evalution_CM(tst_lab, pred_1)\n",
    "        [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2] = perf_evalution_CM(tst_lab, pred_2)\n",
    "        [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3] = perf_evalution_CM(tst_lab, pred_3)\n",
    "        [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4] = perf_evalution_CM(tst_lab, pred_4)\n",
    "        [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5] = perf_evalution_CM(tst_lab, pred_5)\n",
    "        [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6] = perf_evalution_CM(tst_lab, pred_6)\n",
    "        [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7] = perf_evalution_CM(tst_lab, pred_7)\n",
    "        [ACC8, SEN8, SPE8, PRE8, REC8, FMS8, TS8, NPV8, FOR8, MCC8] = perf_evalution_CM(tst_lab, pred_8)\n",
    "        [ACC9, SEN9, SPE9, PRE9, REC9, FMS9, TS9, NPV9, FOR9, MCC9] = perf_evalution_CM(tst_lab, pred_9)\n",
    "        [ACC10, SEN10, SPE10, PRE10, REC10, FMS10, TS10, NPV10, FOR10, MCC10] = perf_evalution_CM(tst_lab, pred_10)\n",
    "        perf_0 = [ACC0, SEN0, SPE0, PRE0, REC0, FMS0, TS0, NPV0, FOR0, MCC0]\n",
    "        perf_1 = [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1]\n",
    "        perf_2 = [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2]\n",
    "        perf_3 = [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3]\n",
    "        perf_4 = [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4]\n",
    "        perf_5 = [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5]\n",
    "        perf_6 = [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6]\n",
    "        perf_7 = [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7]\n",
    "        perf_8 = [ACC8, SEN8, SPE8, PRE8, REC8, FMS8, TS8, NPV8, FOR8, MCC8]\n",
    "        perf_9 = [ACC9, SEN9, SPE9, PRE9, REC9, FMS9, TS9, NPV9, FOR9, MCC9]\n",
    "        perf_10 = [ACC10, SEN10, SPE10, PRE10, REC10, FMS10, TS10, NPV10, FOR10, MCC10]\n",
    "\n",
    "        perf_A.append(perf_0)\n",
    "        perf_B.append(perf_1)\n",
    "        perf_C.append(perf_2)\n",
    "        perf_D.append(perf_3)\n",
    "        perf_E.append(perf_4)\n",
    "        perf_F.append(perf_5)\n",
    "        perf_G.append(perf_6)\n",
    "        perf_H.append(perf_7)\n",
    "        perf_I.append(perf_8)\n",
    "        perf_J.append(perf_9)\n",
    "        perf_K.append(perf_10)\n",
    "\n",
    "        tr_per = tr_per + 0.2\n",
    "    if tt == 0:\n",
    "            np.save('perf_A0', perf_A)\n",
    "            np.save('perf_B0', perf_B)\n",
    "            np.save('perf_C0', perf_C)\n",
    "            np.save('perf_D0', perf_D)\n",
    "            np.save('perf_E0', perf_E)\n",
    "            np.save('perf_F0', perf_F)\n",
    "            np.save('perf_G0', perf_G)\n",
    "            np.save('perf_H0', perf_H)\n",
    "            np.save('perf_I0', perf_I)\n",
    "            np.save('perf_J0', perf_J)\n",
    "            np.save('perf_K0', perf_K)\n",
    "    else:#if tt == 1:\n",
    "            np.save('perf_A1', perf_A)\n",
    "            np.save('perf_B1', perf_B)\n",
    "            np.save('perf_C1', perf_C)\n",
    "            np.save('perf_D1', perf_D)\n",
    "            np.save('perf_E1', perf_E)\n",
    "            np.save('perf_F1', perf_F)\n",
    "            np.save('perf_G1', perf_G)\n",
    "            np.save('perf_H1', perf_H)\n",
    "            np.save('perf_I1', perf_I)\n",
    "            np.save('perf_J1', perf_J)\n",
    "            np.save('perf_K1', perf_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perf_Evaluation_RoC_AUC_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,tt):\n",
    "    tr_per = 0.85\n",
    "    epoch = 50\n",
    "    perf_A = []\n",
    "    perf_B = []\n",
    "    perf_C = []\n",
    "    perf_D = []\n",
    "    perf_E = []\n",
    "    perf_F = []\n",
    "    perf_G = []\n",
    "    perf_H = []\n",
    "    perf_I = []\n",
    "    perf_J = []\n",
    "    perf_K= []\n",
    "\n",
    "    for a in range(0,1):\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat, Final_Lab, tr_per)\n",
    "        pred_0,Model_0=main_SVM_Classifier(tr_data, tr_lab, tst_data)######SVM Classifier\n",
    "        y_pred_proba = Model_0.predict_proba(tst_data)[::, 1]\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        predicted_proba = Model_0.predict_proba(tst_data)\n",
    "        roc_auc = roc_auc_score(tst_lab, predicted_proba, multi_class='ovo')\n",
    "        fpr, tpr, _ = metrics.roc_curve(tst_lab, y_pred_proba)\n",
    "        auc = metrics.roc_auc_score(tst_lab, y_pred_proba)\n",
    "\n",
    "        pred_1,Model_1=main_SAE_LSTM(tr_data, tr_lab, tst_data, epoch)######  SAE-LSTM Classifier\n",
    "        pred_2,Model_2 = main_KNN_Classifier_ROC_AUC(tr_data, tr_lab, tst_data)######  Knn Classifier\n",
    "        pred_3,Model_3 = main_CNN_LSTM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, epoch)######  CNN-LSTM Classifier\n",
    "        pred_4,Model_4 = main_LightGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data)######  LightGBM Classifier\n",
    "        pred_5,Model_5 = main_AdaBoost_Classifier_ROC_AUC(tr_data, tr_lab, tst_data)######  Adaboost Classifier\n",
    "        pred_6,Model_6 = main_BiLSTM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, epoch)######  BiLSTM Classifier\n",
    "        pred_7,Model_7 = main_BiLSTM_LiGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, tst_lab, 0, epoch)######  PSO Tuned BiLSTM Classifier\n",
    "        pred_8,Model_8 = main_BiLSTM_LiGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, tst_lab, 1, epoch)######  SSO Tuned BiLSTM Classifier\n",
    "        pred_9,Model_9 = main_BiLSTM_LiGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, tst_lab, 2, epoch)######  HHO Tuned BiLSTM Classifier\n",
    "        pred_10,Model_10 = main_BiLSTM_LiGBM_Classifier_Mod_ROC_AUC(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)######  Proposed Tuned BiLSTM Classifier\n",
    "        ################   Performance Extraction Using Confusion Matrix   ###############\n",
    "        [ACC0, SEN0, SPE0, PRE0, REC0, FMS0, TS0, NPV0, FOR0, MCC0] = perf_evalution_CM(tst_lab, pred_0)\n",
    "        [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1] = perf_evalution_CM(tst_lab, pred_1)\n",
    "        [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2] = perf_evalution_CM(tst_lab, pred_2)\n",
    "        [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3] = perf_evalution_CM(tst_lab, pred_3)\n",
    "        [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4] = perf_evalution_CM(tst_lab, pred_4)\n",
    "        [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5] = perf_evalution_CM(tst_lab, pred_5)\n",
    "        [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6] = perf_evalution_CM(tst_lab, pred_6)\n",
    "        [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7] = perf_evalution_CM(tst_lab, pred_7)\n",
    "        [ACC8, SEN8, SPE8, PRE8, REC8, FMS8, TS8, NPV8, FOR8, MCC8] = perf_evalution_CM(tst_lab, pred_8)\n",
    "        [ACC9, SEN9, SPE9, PRE9, REC9, FMS9, TS9, NPV9, FOR9, MCC9] = perf_evalution_CM(tst_lab, pred_9)\n",
    "        [ACC10, SEN10, SPE10, PRE10, REC10, FMS10, TS10, NPV10, FOR10, MCC10] = perf_evalution_CM(tst_lab, pred_10)\n",
    "        perf_0 = [ACC0, SEN0, SPE0, PRE0, REC0, FMS0, TS0, NPV0, FOR0, MCC0]\n",
    "        perf_1 = [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1]\n",
    "        perf_2 = [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2]\n",
    "        perf_3 = [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3]\n",
    "        perf_4 = [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4]\n",
    "        perf_5 = [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5]\n",
    "        perf_6 = [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6]\n",
    "        perf_7 = [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7]\n",
    "        perf_8 = [ACC8, SEN8, SPE8, PRE8, REC8, FMS8, TS8, NPV8, FOR8, MCC8]\n",
    "        perf_9 = [ACC9, SEN9, SPE9, PRE9, REC9, FMS9, TS9, NPV9, FOR9, MCC9]\n",
    "        perf_10 = [ACC10, SEN10, SPE10, PRE10, REC10, FMS10, TS10, NPV10, FOR10, MCC10]\n",
    "\n",
    "        perf_A.append(perf_0)\n",
    "        perf_B.append(perf_1)\n",
    "        perf_C.append(perf_2)\n",
    "        perf_D.append(perf_3)\n",
    "        perf_E.append(perf_4)\n",
    "        perf_F.append(perf_5)\n",
    "        perf_G.append(perf_6)\n",
    "        perf_H.append(perf_7)\n",
    "        perf_I.append(perf_8)\n",
    "        perf_J.append(perf_9)\n",
    "        perf_K.append(perf_10)\n",
    "        tr_per = tr_per + 0.1\n",
    "    if tt == 0:\n",
    "            np.save('ROC_AUC_perf_A0', perf_A)\n",
    "            np.save('ROC_AUC_perf_B0', perf_B)\n",
    "            np.save('ROC_AUC_perf_C0', perf_C)\n",
    "            np.save('ROC_AUC_perf_D0', perf_D)\n",
    "            np.save('ROC_AUC_perf_E0', perf_E)\n",
    "            np.save('ROC_AUC_perf_F0', perf_F)\n",
    "            np.save('ROC_AUC_perf_G0', perf_G)\n",
    "            np.save('ROC_AUC_perf_H0', perf_H)\n",
    "            np.save('ROC_AUC_perf_I0', perf_I)\n",
    "            np.save('ROC_AUC_perf_J1', perf_J)\n",
    "            np.save('ROC_AUC_perf_K1', perf_K)\n",
    "    else:#if tt == 1:\n",
    "            np.save('ROC_AUC_perf_A1', perf_A)\n",
    "            np.save('ROC_AUC_perf_B1', perf_B)\n",
    "            np.save('ROC_AUC_perf_C1', perf_C)\n",
    "            np.save('ROC_AUC_perf_D1', perf_D)\n",
    "            np.save('ROC_AUC_perf_E1', perf_E)\n",
    "            np.save('ROC_AUC_perf_F1', perf_F)\n",
    "            np.save('ROC_AUC_perf_G1', perf_G)\n",
    "            np.save('ROC_AUC_perf_H1', perf_H)\n",
    "            np.save('ROC_AUC_perf_I1', perf_I)\n",
    "            np.save('ROC_AUC_perf_J1', perf_J)\n",
    "            np.save('ROC_AUC_perf_K1', perf_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve,roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "def Perf_Evaluation_PRC_AUC_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,tt):\n",
    "    tr_per = 0.85\n",
    "    epoch = 1\n",
    "    perf_A = []\n",
    "    perf_B = []\n",
    "    perf_C = []\n",
    "    perf_D = []\n",
    "    perf_E = []\n",
    "    perf_F = []\n",
    "    perf_G = []\n",
    "    perf_H = []\n",
    "    perf_I = []\n",
    "    perf_J = []\n",
    "    perf_K= []\n",
    "\n",
    "    for a in range(0,1):\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat, Final_Lab, tr_per)\n",
    "        # pred_0,Model_0=main_SVM_Classifier(tr_data, tr_lab, tst_data)######SVM Classifier\n",
    "        # y_pred_proba = Model_0.predict_proba(tst_data)[::, 1]\n",
    "        pred_4,Model_4 = main_LightGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data)######  LightGBM Classifier\n",
    "\n",
    "        predicted_proba = Model_4.predict_proba(tst_data)\n",
    "        # roc_auc = roc_auc_score(tst_lab, predicted_proba, multi_class='ovo')\n",
    "        # precision recall curve\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        n_classes=5\n",
    "        y_test=label_binarize(tst_lab, classes=[*range(n_classes)])\n",
    "        for i in range(n_classes):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],predicted_proba[:, i])\n",
    "            plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "\n",
    "        plt.xlabel(\"recall\")\n",
    "        plt.ylabel(\"precision\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.title(\"precision vs. recall curve\")\n",
    "        plt.show()\n",
    "\n",
    "        # auc = metrics.roc_auc_score(tst_lab, y_pred_proba)\n",
    "\n",
    "        pred_1,Model_1=main_SAE_LSTM(tr_data, tr_lab, tst_data, epoch)######  SAE-LSTM Classifier\n",
    "        pred_2,Model_2 = main_KNN_Classifier_ROC_AUC(tr_data, tr_lab, tst_data)######  Knn Classifier\n",
    "        pred_3,Model_3 = main_CNN_LSTM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, epoch)######  CNN-LSTM Classifier\n",
    "        pred_4,Model_4 = main_LightGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data)######  LightGBM Classifier\n",
    "        pred_5,Model_5 = main_AdaBoost_Classifier_ROC_AUC(tr_data, tr_lab, tst_data)######  Adaboost Classifier\n",
    "        pred_6,Model_6 = main_BiLSTM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, epoch)######  BiLSTM Classifier\n",
    "        pred_7,Model_7 = main_BiLSTM_LiGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, tst_lab, 0, epoch)######  PSO Tuned BiLSTM Classifier\n",
    "        pred_8,Model_8 = main_BiLSTM_LiGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, tst_lab, 1, epoch)######  SSO Tuned BiLSTM Classifier\n",
    "        pred_9,Model_9 = main_BiLSTM_LiGBM_Classifier_ROC_AUC(tr_data, tr_lab, tst_data, tst_lab, 2, epoch)######  HHO Tuned BiLSTM Classifier\n",
    "        pred_10,Model_10 = main_BiLSTM_LiGBM_Classifier_Mod_ROC_AUC(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)######  Proposed Tuned BiLSTM Classifier\n",
    "        ################   Performance Extraction Using Confusion Matrix   ###############\n",
    "        [ACC0, SEN0, SPE0, PRE0, REC0, FMS0, TS0, NPV0, FOR0, MCC0] = perf_evalution_CM(tst_lab, pred_0)\n",
    "        [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1] = perf_evalution_CM(tst_lab, pred_1)\n",
    "        [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2] = perf_evalution_CM(tst_lab, pred_2)\n",
    "        [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3] = perf_evalution_CM(tst_lab, pred_3)\n",
    "        [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4] = perf_evalution_CM(tst_lab, pred_4)\n",
    "        [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5] = perf_evalution_CM(tst_lab, pred_5)\n",
    "        [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6] = perf_evalution_CM(tst_lab, pred_6)\n",
    "        [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7] = perf_evalution_CM(tst_lab, pred_7)\n",
    "        [ACC8, SEN8, SPE8, PRE8, REC8, FMS8, TS8, NPV8, FOR8, MCC8] = perf_evalution_CM(tst_lab, pred_8)\n",
    "        [ACC9, SEN9, SPE9, PRE9, REC9, FMS9, TS9, NPV9, FOR9, MCC9] = perf_evalution_CM(tst_lab, pred_9)\n",
    "        [ACC10, SEN10, SPE10, PRE10, REC10, FMS10, TS10, NPV10, FOR10, MCC10] = perf_evalution_CM(tst_lab, pred_10)\n",
    "        perf_0 = [ACC0, SEN0, SPE0, PRE0, REC0, FMS0, TS0, NPV0, FOR0, MCC0]\n",
    "        perf_1 = [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1]\n",
    "        perf_2 = [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2]\n",
    "        perf_3 = [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3]\n",
    "        perf_4 = [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4]\n",
    "        perf_5 = [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5]\n",
    "        perf_6 = [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6]\n",
    "        perf_7 = [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7]\n",
    "        perf_8 = [ACC8, SEN8, SPE8, PRE8, REC8, FMS8, TS8, NPV8, FOR8, MCC8]\n",
    "        perf_9 = [ACC9, SEN9, SPE9, PRE9, REC9, FMS9, TS9, NPV9, FOR9, MCC9]\n",
    "        perf_10 = [ACC10, SEN10, SPE10, PRE10, REC10, FMS10, TS10, NPV10, FOR10, MCC10]\n",
    "\n",
    "        perf_A.append(perf_0)\n",
    "        perf_B.append(perf_1)\n",
    "        perf_C.append(perf_2)\n",
    "        perf_D.append(perf_3)\n",
    "        perf_E.append(perf_4)\n",
    "        perf_F.append(perf_5)\n",
    "        perf_G.append(perf_6)\n",
    "        perf_H.append(perf_7)\n",
    "        perf_I.append(perf_8)\n",
    "        perf_J.append(perf_9)\n",
    "        perf_K.append(perf_10)\n",
    "        tr_per = tr_per + 0.1\n",
    "    if tt == 0:\n",
    "            np.save('PRC_AUC_perf_A0', perf_A)\n",
    "            np.save('PRC_AUC_perf_B0', perf_B)\n",
    "            np.save('PRC_AUC_perf_C0', perf_C)\n",
    "            np.save('PRC_AUC_perf_D0', perf_D)\n",
    "            np.save('PRC_AUC_perf_E0', perf_E)\n",
    "            np.save('PRC_AUC_perf_F0', perf_F)\n",
    "            np.save('PRC_AUC_perf_G0', perf_G)\n",
    "            np.save('PRC_AUC_perf_H0', perf_H)\n",
    "            np.save('PRC_AUC_perf_I0', perf_I)\n",
    "            np.save('PRC_AUC_perf_J1', perf_J)\n",
    "            np.save('PRC_AUC_perf_K1', perf_K)\n",
    "    else:#if tt == 1:\n",
    "            np.save('PRC_AUC_perf_A1', perf_A)\n",
    "            np.save('PRC_AUC_perf_B1', perf_B)\n",
    "            np.save('PRC_AUC_perf_C1', perf_C)\n",
    "            np.save('PRC_AUC_perf_D1', perf_D)\n",
    "            np.save('PRC_AUC_perf_E1', perf_E)\n",
    "            np.save('PRC_AUC_perf_F1', perf_F)\n",
    "            np.save('PRC_AUC_perf_G1', perf_G)\n",
    "            np.save('PRC_AUC_perf_H1', perf_H)\n",
    "            np.save('PRC_AUC_perf_I1', perf_I)\n",
    "            np.save('PRC_AUC_perf_J1', perf_J)\n",
    "            np.save('PRC_AUC_perf_K1', perf_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prop_Identifier_Perf_Evaluation_save_all_final(Sel_identifier_0,Sel_identifier_1,Sel_identifier_2,Sel_identifier_3, Final_Feat, Final_Lab,tt):\n",
    "    tr_per = 0.4\n",
    "    epoch = 50\n",
    "    perf_A = []\n",
    "    perf_B = []\n",
    "    perf_C = []\n",
    "    perf_D = []\n",
    "\n",
    "    for a in range(0,3):\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_0, Final_Feat, Final_Lab, tr_per)\n",
    "        pred_1 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_1, Final_Feat, Final_Lab, tr_per)\n",
    "        pred_2 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_2, Final_Feat, Final_Lab, tr_per)\n",
    "        pred_3 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat, Final_Lab, tr_per)\n",
    "        pred_4 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "\n",
    "        [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1] = perf_evalution_CM(tst_lab, pred_1)\n",
    "        [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2] = perf_evalution_CM(tst_lab, pred_2)\n",
    "        [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3] = perf_evalution_CM(tst_lab, pred_3)\n",
    "        [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4] = perf_evalution_CM(tst_lab, pred_4)\n",
    "\n",
    "        perf_1 = [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1]\n",
    "        perf_2 = [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2]\n",
    "        perf_3 = [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3]\n",
    "        perf_4 = [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4]\n",
    "\n",
    "        perf_A.append(perf_1)\n",
    "        perf_B.append(perf_2)\n",
    "        perf_C.append(perf_3)\n",
    "        perf_D.append(perf_4)\n",
    "\n",
    "        tr_per = tr_per + 0.2\n",
    "    if tt == 0:\n",
    "            np.save('Identifier_perf_A0', perf_A)\n",
    "            np.save('Identifier_perf_B0', perf_B)\n",
    "            np.save('Identifier_perf_C0', perf_C)\n",
    "            np.save('Identifier_perf_D0', perf_D)\n",
    "    else:#if tt == 1:\n",
    "            np.save('Identifier_perf_A1', perf_A)\n",
    "            np.save('Identifier_perf_B1', perf_B)\n",
    "            np.save('Identifier_perf_C1', perf_C)\n",
    "            np.save('Identifier_perf_D1', perf_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prop_Data_balancing_Perf_Evaluation_save_all_final(Sel_identifier_3,Final_Feat, Final_Lab,tt):\n",
    "    # Final_Feat, Final_Lab = main_output_all_Data_Balancing(0, id, Final_Feat, Final_Lab)\n",
    "\n",
    "    Final_Feat1, Final_Lab1 = main_output_all_Data_Balancing(0, 0, Final_Feat, Final_Lab)\n",
    "    Final_Feat2, Final_Lab2 = main_output_all_Data_Balancing(0, 1, Final_Feat, Final_Lab)\n",
    "    Final_Feat3, Final_Lab3 = main_output_all_Data_Balancing(0, 2, Final_Feat, Final_Lab)\n",
    "    Final_Feat4, Final_Lab4 = main_output_all_Data_Balancing(0, 3, Final_Feat, Final_Lab)\n",
    "    Final_Feat5, Final_Lab5 = main_output_all_Data_Balancing(0, 4, Final_Feat, Final_Lab)\n",
    "    Final_Feat6, Final_Lab6 = main_output_all_Data_Balancing(0, 5, Final_Feat, Final_Lab)\n",
    "    Final_Feat7, Final_Lab7 = main_output_all_Data_Balancing(0, 6, Final_Feat, Final_Lab)\n",
    "\n",
    "    tr_per = 0.4\n",
    "    epoch = 50\n",
    "    perf_A = []\n",
    "    perf_B = []\n",
    "    perf_C = []\n",
    "    perf_D = []\n",
    "    perf_E = []\n",
    "    perf_F = []\n",
    "    perf_G = []\n",
    "\n",
    "    for a in range(0,3):\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat1, Final_Lab1, tr_per)\n",
    "        pred_1 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1] = perf_evalution_CM(tst_lab, pred_1)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat2, Final_Lab2, tr_per)\n",
    "        pred_2 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2] = perf_evalution_CM(tst_lab, pred_2)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat3, Final_Lab3, tr_per)\n",
    "        pred_3 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3] = perf_evalution_CM(tst_lab, pred_3)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat4, Final_Lab4, tr_per)\n",
    "        pred_4 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4] = perf_evalution_CM(tst_lab, pred_4)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat5, Final_Lab5, tr_per)\n",
    "        pred_5 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5] = perf_evalution_CM(tst_lab, pred_5)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat6, Final_Lab6, tr_per)\n",
    "        pred_6 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6] = perf_evalution_CM(tst_lab, pred_6)\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat7, Final_Lab7, tr_per)\n",
    "        pred_7 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, epoch)\n",
    "        [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7] = perf_evalution_CM(tst_lab, pred_7)\n",
    "\n",
    "        perf_1 = [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1]\n",
    "        perf_2 = [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2]\n",
    "        perf_3 = [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3]\n",
    "        perf_4 = [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4]\n",
    "        perf_5 = [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5]\n",
    "        perf_6 = [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6]\n",
    "        perf_7 = [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7]\n",
    "\n",
    "\n",
    "        perf_A.append(perf_1)\n",
    "        perf_B.append(perf_2)\n",
    "        perf_C.append(perf_3)\n",
    "        perf_D.append(perf_4)\n",
    "        perf_E.append(perf_5)\n",
    "        perf_F.append(perf_6)\n",
    "        perf_G.append(perf_7)\n",
    "\n",
    "\n",
    "        tr_per = tr_per + 0.2\n",
    "    if tt == 0:\n",
    "        np.save('Data_Bal_perf_A0', perf_A)\n",
    "        np.save('Data_Bal_perf_B0', perf_B)\n",
    "        np.save('Data_Bal_perf_C0', perf_C)\n",
    "        np.save('Data_Bal_perf_D0', perf_D)\n",
    "        np.save('Data_Bal_perf_E0', perf_E)\n",
    "        np.save('Data_Bal_perf_F0', perf_F)\n",
    "        np.save('Data_Bal_perf_G0', perf_G)\n",
    "\n",
    "    else:  # if tt == 1:\n",
    "        np.save('Data_Bal_perf_A1', perf_A)\n",
    "        np.save('Data_Bal_perf_B1', perf_B)\n",
    "        np.save('Data_Bal_perf_C1', perf_C)\n",
    "        np.save('Data_Bal_perf_D1', perf_D)\n",
    "        np.save('Data_Bal_perf_E1', perf_E)\n",
    "        np.save('Data_Bal_perf_F1', perf_F)\n",
    "        np.save('Data_Bal_perf_G1', perf_G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prop_Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,tt):\n",
    "    tr_per = 0.4\n",
    "    # epoch = 1\n",
    "    perf_A = []\n",
    "    perf_B = []\n",
    "    perf_C = []\n",
    "    perf_D = []\n",
    "    perf_E = []\n",
    "\n",
    "    for a in range(0,3):\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat, Final_Lab, tr_per)\n",
    "\n",
    "        pred_1 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 1)\n",
    "        pred_2 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 2)\n",
    "        pred_3 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 3)\n",
    "        pred_4 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 4)\n",
    "        pred_5 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 5)\n",
    "\n",
    "        [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1] = perf_evalution_CM(tst_lab, pred_1)\n",
    "        [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2] = perf_evalution_CM(tst_lab, pred_2)\n",
    "        [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3] = perf_evalution_CM(tst_lab, pred_3)\n",
    "        [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4] = perf_evalution_CM(tst_lab, pred_4)\n",
    "        [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5] = perf_evalution_CM(tst_lab, pred_5)\n",
    "\n",
    "        perf_1 = [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1]\n",
    "        perf_2 = [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2]\n",
    "        perf_3 = [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3]\n",
    "        perf_4 = [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4]\n",
    "        perf_5 = [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5]\n",
    "\n",
    "\n",
    "        perf_A.append(perf_1)\n",
    "        perf_B.append(perf_2)\n",
    "        perf_C.append(perf_3)\n",
    "        perf_D.append(perf_4)\n",
    "        perf_E.append(perf_5)\n",
    "\n",
    "        tr_per = tr_per + 0.2\n",
    "    if tt == 0:\n",
    "            np.save('Pro_perf_A0', perf_A)\n",
    "            np.save('Pro_perf_B0', perf_B)\n",
    "            np.save('Pro_perf_C0', perf_C)\n",
    "            np.save('Pro_perf_D0', perf_D)\n",
    "            np.save('Pro_perf_E0', perf_E)\n",
    "    else:#if tt == 1:\n",
    "            np.save('Pro_perf_A1', perf_A)\n",
    "            np.save('Pro_perf_B1', perf_B)\n",
    "            np.save('Pro_perf_C1', perf_C)\n",
    "            np.save('Pro_perf_D1', perf_D)\n",
    "            np.save('Pro_perf_E1', perf_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KF_Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,tt):\n",
    "    # tr_per = 0.4\n",
    "    perf_A = []\n",
    "    perf_B = []\n",
    "    perf_C = []\n",
    "    perf_D = []\n",
    "    perf_E = []\n",
    "    perf_F = []\n",
    "    perf_G = []\n",
    "    perf_H = []\n",
    "    perf_I = []\n",
    "    perf_J = []\n",
    "    perf_K = []\n",
    "\n",
    "    epoch = 50\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kval=6\n",
    "    for a in range(3):\n",
    "        strtfdKFold = StratifiedKFold(n_splits=kval)\n",
    "        kfold = strtfdKFold.split(Final_Feat, Final_Lab)\n",
    "        perf_A1 = []\n",
    "        perf_B1 = []\n",
    "        perf_C1 = []\n",
    "        perf_D1 = []\n",
    "        perf_E1 = []\n",
    "        perf_F1 = []\n",
    "        perf_G1 = []\n",
    "        perf_H1 = []\n",
    "        perf_I1 = []\n",
    "        perf_J1 = []\n",
    "        perf_K1 = []\n",
    "\n",
    "        for k, (train, test) in enumerate(kfold):\n",
    "            tr_data=Final_Feat.iloc[train, Sel_identifier_3]\n",
    "            tr_lab=Final_Lab.iloc[train]\n",
    "            tst_data=Final_Feat.iloc[test,Sel_identifier_3]\n",
    "            tst_lab=Final_Lab.iloc[test]\n",
    "            # tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat, Final_Lab, tr_per)\n",
    "            pred_1 = main_SVM_Classifier(tr_data, tr_lab, tst_data)  ######SVM Classifier\n",
    "            pred_2 = main_SAE_LSTM(tr_data, tr_lab, tst_data, epoch)  ######  SAE-LSTM Classifier\n",
    "            pred_3 = main_KNN_Classifier(tr_data, tr_lab, tst_data)  ######  Knn Classifier\n",
    "            pred_4 = main_CNN_LSTM_Classifier(tr_data, tr_lab, tst_data, epoch)  ######  CNN-LSTM Classifier\n",
    "            pred_5 = main_LightGBM_Classifier(tr_data, tr_lab, tst_data)  ######  LightGBM Classifier\n",
    "            pred_6 = main_AdaBoost_Classifier(tr_data, tr_lab, tst_data)  ######  Adaboost Classifier\n",
    "            pred_7 = main_BiLSTM_Classifier(tr_data, tr_lab, tst_data, epoch)  ######  BiLSTM Classifier\n",
    "            pred_8 = main_BiLSTM_LiGBM_Classifier(tr_data, tr_lab, tst_data, tst_lab, 0,\n",
    "                                                  epoch)  ######  PSO Tuned BiLSTM Classifier\n",
    "            pred_9 = main_BiLSTM_LiGBM_Classifier(tr_data, tr_lab, tst_data, tst_lab, 1,\n",
    "                                                  epoch)  ######  SSO Tuned BiLSTM Classifier\n",
    "            pred_10 = main_BiLSTM_LiGBM_Classifier(tr_data, tr_lab, tst_data, tst_lab, 2,\n",
    "                                                  epoch)  ######  HHO Tuned BiLSTM Classifier\n",
    "            pred_11 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3,\n",
    "                                                       epoch)  ######  Proposed Tuned BiLSTM Classifier\n",
    "\n",
    "            [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1] = perf_evalution_CM(tst_lab, pred_1)\n",
    "            [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2] = perf_evalution_CM(tst_lab, pred_2)\n",
    "            [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3] = perf_evalution_CM(tst_lab, pred_3)\n",
    "            [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4] = perf_evalution_CM(tst_lab, pred_4)\n",
    "            [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5] = perf_evalution_CM(tst_lab, pred_5)\n",
    "            [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6] = perf_evalution_CM(tst_lab, pred_6)\n",
    "            [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7] = perf_evalution_CM(tst_lab, pred_7)\n",
    "            [ACC8, SEN8, SPE8, PRE8, REC8, FMS8, TS8, NPV8, FOR8, MCC8] = perf_evalution_CM(tst_lab, pred_8)\n",
    "            [ACC9, SEN9, SPE9, PRE9, REC9, FMS9, TS9, NPV9, FOR9, MCC9] = perf_evalution_CM(tst_lab, pred_9)\n",
    "            [ACC10, SEN10, SPE10, PRE10, REC10, FMS10, TS10, NPV10, FOR10, MCC10] = perf_evalution_CM(tst_lab, pred_10)\n",
    "            [ACC11, SEN11, SPE11, PRE11, REC11, FMS11, TS11, NPV11, FOR11, MCC11] = perf_evalution_CM(tst_lab, pred_11)\n",
    "\n",
    "            perf_1 = [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1]\n",
    "            perf_2 = [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2]\n",
    "            perf_3 = [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3]\n",
    "            perf_4 = [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4]\n",
    "            perf_5 = [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5]\n",
    "            perf_6 = [ACC6, SEN6, SPE6, PRE6, REC6, FMS6, TS6, NPV6, FOR6, MCC6]\n",
    "            perf_7 = [ACC7, SEN7, SPE7, PRE7, REC7, FMS7, TS7, NPV7, FOR7, MCC7]\n",
    "            perf_8 = [ACC8, SEN8, SPE8, PRE8, REC8, FMS8, TS8, NPV8, FOR8, MCC8]\n",
    "            perf_9 = [ACC9, SEN9, SPE9, PRE9, REC9, FMS9, TS9, NPV9, FOR9, MCC9]\n",
    "            perf_10 = [ACC10, SEN10, SPE10, PRE10, REC10, FMS10, TS10, NPV10, FOR10, MCC10]\n",
    "            perf_11 = [ACC11, SEN11, SPE11, PRE11, REC11, FMS11, TS11, NPV11, FOR11, MCC11]\n",
    "\n",
    "            perf_A1.append(perf_1)\n",
    "            perf_B1.append(perf_2)\n",
    "            perf_C1.append(perf_3)\n",
    "            perf_D1.append(perf_4)\n",
    "            perf_E1.append(perf_5)\n",
    "            perf_F1.append(perf_6)\n",
    "            perf_G1.append(perf_7)\n",
    "            perf_H1.append(perf_8)\n",
    "            perf_I1.append(perf_9)\n",
    "            perf_J1.append(perf_10)\n",
    "            perf_K1.append(perf_11)\n",
    "            if k==0:\n",
    "                break\n",
    "        perf_A.append(np.mean(np.asarray(perf_A1), axis=0))\n",
    "        perf_B.append(np.mean(np.asarray(perf_B1), axis=0))\n",
    "        perf_C.append(np.mean(np.asarray(perf_C1), axis=0))\n",
    "        perf_D.append(np.mean(np.asarray(perf_D1), axis=0))\n",
    "        perf_E.append(np.mean(np.asarray(perf_E1), axis=0))\n",
    "        perf_F.append(np.mean(np.asarray(perf_F1), axis=0))\n",
    "        perf_G.append(np.mean(np.asarray(perf_G1), axis=0))\n",
    "        perf_H.append(np.mean(np.asarray(perf_H1), axis=0))\n",
    "        perf_I.append(np.mean(np.asarray(perf_I1), axis=0))\n",
    "        perf_J.append(np.mean(np.asarray(perf_J1), axis=0))\n",
    "        perf_K.append(np.mean(np.asarray(perf_K1), axis=0))\n",
    "\n",
    "        kval = kval + 2\n",
    "    if tt == 0:\n",
    "            np.save('KF_perf_A0', perf_A)\n",
    "            np.save('KF_perf_B0', perf_B)\n",
    "            np.save('KF_perf_C0', perf_C)\n",
    "            np.save('KF_perf_D0', perf_D)\n",
    "            np.save('KF_perf_E0', perf_E)\n",
    "            np.save('KF_perf_F0', perf_F)\n",
    "            np.save('KF_perf_G0', perf_G)\n",
    "            np.save('KF_perf_H0', perf_H)\n",
    "            np.save('KF_perf_I0', perf_I)\n",
    "            np.save('KF_perf_J0', perf_J)\n",
    "            np.save('KF_perf_K0', perf_K)\n",
    "    else:#if tt == 1:\n",
    "            np.save('KF_perf_A1', perf_A)\n",
    "            np.save('KF_perf_B1', perf_B)\n",
    "            np.save('KF_perf_C1', perf_C)\n",
    "            np.save('KF_perf_D1', perf_D)\n",
    "            np.save('KF_perf_E1', perf_E)\n",
    "            np.save('KF_perf_F1', perf_F)\n",
    "            np.save('KF_perf_G1', perf_G)\n",
    "            np.save('KF_perf_H1', perf_H)\n",
    "            np.save('KF_perf_I1', perf_I)\n",
    "            np.save('KF_perf_J0', perf_J)\n",
    "            np.save('KF_perf_K0', perf_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prop_KF_Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,tt):\n",
    "    # tr_per = 0.4\n",
    "    perf_A = []\n",
    "    perf_B = []\n",
    "    perf_C = []\n",
    "    perf_D = []\n",
    "    perf_E = []\n",
    "\n",
    "    epoch = 1\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kval=6\n",
    "    for a in range(3):\n",
    "        strtfdKFold = StratifiedKFold(n_splits=kval)\n",
    "        kfold = strtfdKFold.split(Final_Feat, Final_Lab)\n",
    "        perf_A1 = []\n",
    "        perf_B1 = []\n",
    "        perf_C1 = []\n",
    "        perf_D1 = []\n",
    "        perf_E1 = []\n",
    "\n",
    "        for k, (train, test) in enumerate(kfold):\n",
    "            tr_data=Final_Feat[train, :]\n",
    "            tr_data=tr_data[:, Sel_identifier_3]\n",
    "            tr_lab=Final_Lab[train]\n",
    "\n",
    "            tst_data=Final_Feat[test, :]\n",
    "            tst_data=tst_data[:, Sel_identifier_3]\n",
    "            tst_lab=Final_Lab[test]\n",
    "            # tr_data, tr_lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat, Final_Lab, tr_per)\n",
    "            pred_1 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 1)\n",
    "            pred_2 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 2)\n",
    "            pred_3 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 3)\n",
    "            pred_4 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 4)\n",
    "            pred_5 = main_BiLSTM_LiGBM_Classifier_Mod(tr_data, tr_lab, tst_data, tst_lab, 3, 5)\n",
    "\n",
    "            [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1] = perf_evalution_CM(tst_lab, pred_1)\n",
    "            [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2] = perf_evalution_CM(tst_lab, pred_2)\n",
    "            [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3] = perf_evalution_CM(tst_lab, pred_3)\n",
    "            [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4] = perf_evalution_CM(tst_lab, pred_4)\n",
    "            [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5] = perf_evalution_CM(tst_lab, pred_5)\n",
    "\n",
    "\n",
    "            perf_1 = [ACC1, SEN1, SPE1, PRE1, REC1, FMS1, TS1, NPV1, FOR1, MCC1]\n",
    "            perf_2 = [ACC2, SEN2, SPE2, PRE2, REC2, FMS2, TS2, NPV2, FOR2, MCC2]\n",
    "            perf_3 = [ACC3, SEN3, SPE3, PRE3, REC3, FMS3, TS3, NPV3, FOR3, MCC3]\n",
    "            perf_4 = [ACC4, SEN4, SPE4, PRE4, REC4, FMS4, TS4, NPV4, FOR4, MCC4]\n",
    "            perf_5 = [ACC5, SEN5, SPE5, PRE5, REC5, FMS5, TS5, NPV5, FOR5, MCC5]\n",
    "\n",
    "\n",
    "            perf_A1.append(perf_1)\n",
    "            perf_B1.append(perf_2)\n",
    "            perf_C1.append(perf_3)\n",
    "            perf_D1.append(perf_4)\n",
    "            perf_E1.append(perf_5)\n",
    "            if k==0:\n",
    "                break\n",
    "        perf_A.append(np.mean(np.asarray(perf_A1), axis=0))\n",
    "        perf_B.append(np.mean(np.asarray(perf_B1), axis=0))\n",
    "        perf_C.append(np.mean(np.asarray(perf_C1), axis=0))\n",
    "        perf_D.append(np.mean(np.asarray(perf_D1), axis=0))\n",
    "        perf_E.append(np.mean(np.asarray(perf_E1), axis=0))\n",
    "        kval = kval + 2\n",
    "    if tt == 0:\n",
    "            np.save('Prop_KF_perf_A0', perf_A)\n",
    "            np.save('Prop_KF_perf_B0', perf_B)\n",
    "            np.save('Prop_KF_perf_C0', perf_C)\n",
    "            np.save('Prop_KF_perf_D0', perf_D)\n",
    "            np.save('Prop_KF_perf_E0', perf_E)\n",
    "\n",
    "    else:#if tt == 1:\n",
    "            np.save('Prop_KF_perf_A1', perf_A)\n",
    "            np.save('Prop_KF_perf_B1', perf_B)\n",
    "            np.save('Prop_KF_perf_C1', perf_C)\n",
    "            np.save('Prop_KF_perf_D1', perf_D)\n",
    "            np.save('Prop_KF_perf_E1', perf_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_load_org_data(t):\n",
    "    if t==1:\n",
    "        df1 = pd.read_csv(os.getcwd() + '\\DB\\csv_enp0s3-monday.pcap_Flow.csv')\n",
    "        df2 = pd.read_csv(os.getcwd() + '\\DB\\csv_enp0s3-public-tuesday.pcap_Flow.csv')\n",
    "        df3 = pd.read_csv(os.getcwd() + '\\DB\\csv_enp0s3-public-wednesday.pcap_Flow.csv')\n",
    "        df4 = pd.read_csv(os.getcwd() + '\\DB\\csv_enp0s3-public-thursday.pcap_Flow.csv')\n",
    "        df5 = pd.read_csv(os.getcwd() + '\\DB\\csv_enp0s3-tcpdump-friday.pcap_Flow.csv')\n",
    "\n",
    "        tem_feat_1 = df1.values\n",
    "        tem_feat_2 = df2.values\n",
    "        tem_feat_3 = df3.values\n",
    "        tem_feat_4 = df4.values\n",
    "        tem_feat_5 = df5.values\n",
    "        ############   Combine All Data   #############\n",
    "        tem_feat = np.vstack((tem_feat_1, tem_feat_2, tem_feat_3, tem_feat_4, tem_feat_5))\n",
    "        tem_lab = tem_feat[:, -1]\n",
    "        Str_lab = np.unique(tem_feat[:, -1])\n",
    "\n",
    "        fin_feat_1 = main_lab_change(tem_feat_1, Str_lab)\n",
    "        fin_feat_2 = main_lab_change(tem_feat_2, Str_lab)\n",
    "        fin_feat_3 = main_lab_change(tem_feat_3, Str_lab)\n",
    "        fin_feat_4 = main_lab_change(tem_feat_4, Str_lab)\n",
    "        fin_feat_5 = main_lab_change(tem_feat_5, Str_lab)\n",
    "        fin_feat = np.vstack((fin_feat_1, fin_feat_2, fin_feat_3, fin_feat_4, fin_feat_5))\n",
    "        fin_feat = np.asarray(fin_feat, dtype=float)\n",
    "\n",
    "        Final_Feat = fin_feat[:, :-2]\n",
    "        Final_Lab = np.asarray(fin_feat[:, -1], dtype=int)\n",
    "        ###########Time domain-based statistical feature extraction + Data attributes#####################\n",
    "        Final_Feat = main_feature_combine(Final_Feat)  #####Time domain based Features (statistical Features )Extraction\n",
    "        np.save(\"Org_Feat_WO_Balancing.npy\", Final_Feat)\n",
    "        np.save(\"Org_Lab_WO_Balancing.npy\", Final_Lab)\n",
    "\n",
    "    else:\n",
    "        Final_Feat = np.load('Org_Feat_WO_Balancing.npy')\n",
    "        Final_Lab = np.load('Org_Lab_WO_Balancing.npy')\n",
    "    return Final_Feat,Final_Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_find_Identifier_basef_FS(t,Final_Feat, Final_Lab):\n",
    "    if t==1:\n",
    "        tot_attacks = np.unique(Final_Lab)\n",
    "        tr_per = 0.75\n",
    "        tr_data, tr_lab, tst_data, tst_lab = main_data_splitup_tem(tot_attacks,Final_Feat, Final_Lab,\n",
    "                                                                   tr_per)  ######  Data splitup for Attribute Selection\n",
    "        # ##########Quasi identifier detection-based Risk attribute detection and pre-processing  #############\n",
    "        Sel_identifier_0 = prop_Important_Identifier_Detection(tr_data, tr_lab, tst_data, tst_lab, 0, jfs_0)  #####GA\n",
    "        Sel_identifier_1 = prop_Important_Identifier_Detection(tr_data, tr_lab, tst_data, tst_lab, 0, jfs_1)  #####SSA\n",
    "        Sel_identifier_2 = prop_Important_Identifier_Detection(tr_data, tr_lab, tst_data, tst_lab, 0, jfs_2)  ######HHO\n",
    "        Sel_identifier_3 = prop_Important_Identifier_Detection(tr_data, tr_lab, tst_data, tst_lab, 0, jfs_3)  #####Prop\n",
    "        np.save(\"Sel_identifier_0.npy\", Sel_identifier_0)\n",
    "        np.save(\"Sel_identifier_1.npy\", Sel_identifier_1)\n",
    "        np.save(\"Sel_identifier_2.npy\", Sel_identifier_2)\n",
    "        np.save(\"Sel_identifier_3.npy\", Sel_identifier_3)\n",
    "    else:\n",
    "        Sel_identifier_0 = np.load('Sel_identifier_0.npy')\n",
    "        Sel_identifier_1 = np.load('Sel_identifier_1.npy')\n",
    "        Sel_identifier_2 = np.load('Sel_identifier_2.npy')\n",
    "        Sel_identifier_3 = np.load('Sel_identifier_3.npy')\n",
    "    return Sel_identifier_0,Sel_identifier_1,Sel_identifier_2,Sel_identifier_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_output_all_Data_Balancing(t,id,Final_Feat, Final_Lab):\n",
    "    if t==1:\n",
    "            # for id in range(0, 7):\n",
    "        print(id)\n",
    "        Final_Feat, Final_Lab = main_Data_Balancing_optimization(id, Final_Feat, Final_Lab)\n",
    "        if id == 0:\n",
    "                np.save(\"Final_Feat_0.npy\", Final_Feat)\n",
    "                np.save(\"Final_Lab_0.npy\", Final_Lab)\n",
    "        elif id == 1:\n",
    "                np.save(\"Final_Feat_1.npy\", Final_Feat)\n",
    "                np.save(\"Final_Lab_1.npy\", Final_Lab)\n",
    "        elif id == 2:\n",
    "                np.save(\"Final_Feat_2.npy\", Final_Feat)\n",
    "                np.save(\"Final_Lab_2.npy\", Final_Lab)\n",
    "        elif id == 3:\n",
    "                np.save(\"Final_Feat_3.npy\", Final_Feat)\n",
    "                np.save(\"Final_Lab_3.npy\", Final_Lab)\n",
    "        elif id == 4:\n",
    "                np.save(\"Final_Feat_4.npy\", Final_Feat)\n",
    "                np.save(\"Final_Lab_4.npy\", Final_Lab)\n",
    "        elif id == 5:\n",
    "                np.save(\"Final_Feat_5.npy\", Final_Feat)\n",
    "                np.save(\"Final_Lab_5.npy\", Final_Lab)\n",
    "        else:\n",
    "                np.save(\"Final_Feat_6.npy\", Final_Feat)\n",
    "                np.save(\"Final_Lab_6.npy\", Final_Lab)\n",
    "    else:\n",
    "                if id == 0:\n",
    "                    Final_Feat=np.load(\"Final_Feat_0.npy\")\n",
    "                    Final_Lab=np.load(\"Final_Lab_0.npy\")\n",
    "                elif id == 1:\n",
    "                    Final_Feat=np.load(\"Final_Feat_1.npy\")\n",
    "                    Final_Lab=np.load(\"Final_Lab_1.npy\")\n",
    "                elif id == 2:\n",
    "                    Final_Feat=np.load(\"Final_Feat_2.npy\")\n",
    "                    Final_Lab=np.load(\"Final_Lab_2.npy\")\n",
    "                elif id == 3:\n",
    "                    Final_Feat=np.load(\"Final_Feat_3.npy\")\n",
    "                    Final_Lab=np.load(\"Final_Lab_3.npy\")\n",
    "                elif id == 4:\n",
    "                    Final_Feat=np.load(\"Final_Feat_4.npy\")\n",
    "                    Final_Lab=np.load(\"Final_Lab_4.npy\")\n",
    "                elif id == 5:\n",
    "                    Final_Feat=np.load(\"Final_Feat_5.npy\")\n",
    "                    Final_Lab=np.load(\"Final_Lab_5.npy\")\n",
    "                else:\n",
    "                    Final_Feat=np.load(\"Final_Feat_6.npy\")\n",
    "                    Final_Lab=np.load(\"Final_Lab_6.npy\")\n",
    "    return  Final_Feat,Final_Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Complete_Figure_1(x,perf1,perf,val,str_1,xlab,ylab,tt):\n",
    "    perf=perf*100\n",
    "    perf1=perf1*100\n",
    "    AA=np.vstack((np.mean(perf1,axis=1)))\n",
    "    np.savetxt(str(tt)+'_'+str(val)+'_'+'AUC_Graph.csv', AA, delimiter=\",\")\n",
    "    # # data to plot\n",
    "    # n_groups = 5\n",
    "    # # create plot\n",
    "    # fig, ax = plt.subplots()\n",
    "    # index = np.arange(n_groups)\n",
    "    # bar_width = 0.12\n",
    "    # opacity = 0.8\n",
    "    # rects1 = plt.bar(index, perf[0][:], bar_width,alpha=opacity,color='b',label=str_1[0][:])\n",
    "    # rects2 = plt.bar(index + bar_width, perf[1][:], bar_width,alpha=opacity,color='g',label=str_1[1][:])\n",
    "    # rects3 = plt.bar(index + 2*bar_width, perf[2][:], bar_width,alpha=opacity,color='r',label=str_1[2][:])\n",
    "    # rects4 = plt.bar(index + 3*bar_width, perf[3][:], bar_width,alpha=opacity,color='y',label=str_1[3][:])\n",
    "    # rects5 = plt.bar(index + 4*bar_width, perf[4][:], bar_width,alpha=opacity,color='m',label=str_1[4][:])\n",
    "    # rects6 = plt.bar(index + 5*bar_width, perf[5][:], bar_width,alpha=opacity,color='c',label=str_1[5][:])\n",
    "    # rects7 = plt.bar(index + 6*bar_width, perf[6][:], bar_width,alpha=opacity,color='k',label=str_1[6][:])\n",
    "    # rects8 = plt.bar(index + 7*bar_width, perf[7][:], bar_width,alpha=opacity,color=[0.1, 0.3, 0.6],label=str_1[7][:])\n",
    "    #\n",
    "    # plt.xlabel(xlab)\n",
    "    # plt.ylabel(ylab)\n",
    "    # # plt.title('Scores by person')\n",
    "    # plt.xticks(index + bar_width, ('40', '50', '60', '70','80'))\n",
    "    # plt.legend(loc='lower left')\n",
    "    # # plt.tight_layout()\n",
    "    # # plt.show()\n",
    "    # plt.savefig(str(val)+'_'+str(tt)+'_'+'Graph.png', dpi = 800)\n",
    "    # plt.show(block=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    np.savetxt(str(val)+'_'+str(tt)+'_'+'Graph.csv', perf, delimiter=\",\")\n",
    "    plt.figure(val)\n",
    "    plt.plot(x,perf[0][:], color='b', label=str_1[0][:],marker='o', markerfacecolor='m', markersize=6)\n",
    "    plt.plot(x,perf[1][:], color='g', label=str_1[1][:],marker='p', markerfacecolor='k', markersize=6)\n",
    "    plt.plot(x,perf[2][:], color='r', label=str_1[2][:],marker='*', markerfacecolor='g', markersize=6)\n",
    "    plt.plot(x,perf[3][:], color='y', label=str_1[3][:],marker='h', markerfacecolor='r', markersize=6)\n",
    "    plt.plot(x,perf[4][:], color='m', label=str_1[4][:],marker='x', markerfacecolor='g', markersize=6)\n",
    "    plt.plot(x,perf[5][:], color='#47a0b3', label=str_1[5][:],marker='x', markerfacecolor='c', markersize=6)\n",
    "    plt.plot(x,perf[6][:], color='#a2d9a4', label=str_1[6][:],marker='.', markerfacecolor='k', markersize=6)\n",
    "    plt.plot(x,perf[7][:],color='#edf8a3', label=str_1[7][:],marker='.', markerfacecolor='k', markersize=6)\n",
    "    plt.plot(x,perf[8][:],color='c', label=str_1[8][:],marker='.', markerfacecolor='k', markersize=6)\n",
    "    plt.plot(x,perf[9][:],color='#fca55d', label=str_1[9][:],marker='.', markerfacecolor='k', markersize=6)\n",
    "    plt.plot(x,perf[10][:],color='#e2514a', label=str_1[10][:],marker='.', markerfacecolor='k', markersize=6)\n",
    "\n",
    "    #plt.title(\"Performance Statistics\")\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.legend(loc='lower left',ncol=2)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(str(dd)+'_'+str(tt)+'_'+str(val)+'_'+'Graph.png', dpi = 1200)\n",
    "    plt.savefig(str(val)+'_'+str(tt)+'_'+'Graph.png', dpi = 1200)\n",
    "    plt.show(block=False)\n",
    "    plt.close(val)\n",
    "    return perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Complete_Figure_14(x,perf,val,str_1,xlab,ylab,tt):\n",
    "    perf=perf*100\n",
    "    np.savetxt(str(val)+'_'+str(tt)+'_'+'Graph.csv', perf, delimiter=\",\")\n",
    "    # data to plot\n",
    "    n_groups = 3\n",
    "    fig, ax = plt.subplots()\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.15\n",
    "    opacity = 0.8\n",
    "    rects1 = plt.bar(index, perf[0][:], bar_width,alpha=opacity,color='b',label=str_1[0][:])\n",
    "    rects2 = plt.bar(index + bar_width, perf[1][:], bar_width,alpha=opacity,color='g',label=str_1[1][:])\n",
    "    rects3 = plt.bar(index + 2*bar_width, perf[2][:], bar_width,alpha=opacity,color='r',label=str_1[2][:])\n",
    "    rects4 = plt.bar(index + 3*bar_width, perf[3][:], bar_width,alpha=opacity,color='y',label=str_1[3][:])\n",
    "\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.xticks(index + bar_width,x)\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.savefig(str(val)+'_'+str(tt)+'_'+'Graph.png', dpi = 1200)\n",
    "    plt.show(block=False)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Complete_Figure_13(x,perf,val,str_1,xlab,ylab,tt):\n",
    "    perf=perf*100\n",
    "    np.savetxt(str(val)+'_'+str(tt)+'_'+'Graph.csv', perf, delimiter=\",\")\n",
    "    # data to plot\n",
    "    n_groups = 3\n",
    "    fig, ax = plt.subplots()\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.12\n",
    "    opacity = 0.8\n",
    "    rects1 = plt.bar(index, perf[0][:], bar_width,alpha=opacity,color='b',label=str_1[0][:])\n",
    "    rects2 = plt.bar(index + bar_width, perf[1][:], bar_width,alpha=opacity,color='g',label=str_1[1][:])\n",
    "    rects3 = plt.bar(index + 2*bar_width, perf[2][:], bar_width,alpha=opacity,color='r',label=str_1[2][:])\n",
    "    rects4 = plt.bar(index + 3*bar_width, perf[3][:], bar_width,alpha=opacity,color='y',label=str_1[3][:])\n",
    "    rects5 = plt.bar(index + 4*bar_width, perf[4][:], bar_width,alpha=opacity,color='m',label=str_1[4][:])\n",
    "\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.xticks(index + bar_width,x)\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.savefig(str(val)+'_'+str(tt)+'_'+'Graph.png', dpi = 1200)\n",
    "    plt.show(block=False)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Complete_Figure_12(x,perf,val,str_1,xlab,ylab,tt):\n",
    "    perf=perf*100\n",
    "    np.savetxt(str(val)+'_'+str(tt)+'_'+'Graph.csv', perf, delimiter=\",\")\n",
    "    # data to plot\n",
    "    n_groups = 3\n",
    "    fig, ax = plt.subplots()\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.09\n",
    "    opacity = 0.8\n",
    "    rects1 = plt.bar(index, perf[0][:], bar_width,alpha=opacity,color='b',label=str_1[0][:])\n",
    "    rects2 = plt.bar(index + bar_width, perf[1][:], bar_width,alpha=opacity,color='g',label=str_1[1][:])\n",
    "    rects3 = plt.bar(index + 2*bar_width, perf[2][:], bar_width,alpha=opacity,color='r',label=str_1[2][:])\n",
    "    rects4 = plt.bar(index + 3*bar_width, perf[3][:], bar_width,alpha=opacity,color='y',label=str_1[3][:])\n",
    "    rects5 = plt.bar(index + 4*bar_width, perf[4][:], bar_width,alpha=opacity,color='m',label=str_1[4][:])\n",
    "    rects5 = plt.bar(index + 5*bar_width, perf[5][:], bar_width,alpha=opacity,color='#47a0b3',label=str_1[5][:])\n",
    "    rects5 = plt.bar(index + 6*bar_width, perf[6][:], bar_width,alpha=opacity,color='#a2d9a4',label=str_1[6][:])\n",
    "\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.xticks(index + bar_width,x)\n",
    "    plt.legend(loc='lower left',ncol=2)\n",
    "    plt.savefig(str(val)+'_'+str(tt)+'_'+'Graph.png', dpi = 1200)\n",
    "    plt.show(block=False)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Complete_Figure_11(x,perf,val,str_1,xlab,ylab,tt):\n",
    "    perf=perf*100\n",
    "    np.savetxt(str(val)+'_'+str(tt)+'_'+'Graph.csv', perf, delimiter=\",\")\n",
    "    # data to plot\n",
    "    n_groups = 3\n",
    "    fig, ax = plt.subplots()\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.07\n",
    "    opacity = 0.8\n",
    "    rects1 = plt.bar(index, perf[0][:], bar_width,alpha=opacity,color='b',label=str_1[0][:])\n",
    "    rects2 = plt.bar(index + bar_width, perf[1][:], bar_width,alpha=opacity,color='g',label=str_1[1][:])\n",
    "    rects3 = plt.bar(index + 2*bar_width, perf[2][:], bar_width,alpha=opacity,color='r',label=str_1[2][:])\n",
    "    rects4 = plt.bar(index + 3*bar_width, perf[3][:], bar_width,alpha=opacity,color='y',label=str_1[3][:])\n",
    "    rects5 = plt.bar(index + 4*bar_width, perf[4][:], bar_width,alpha=opacity,color='m',label=str_1[4][:])\n",
    "    rects5 = plt.bar(index + 5*bar_width, perf[5][:], bar_width,alpha=opacity,color='#47a0b3',label=str_1[5][:])\n",
    "    rects5 = plt.bar(index + 6*bar_width, perf[6][:], bar_width,alpha=opacity,color='#a2d9a4',label=str_1[6][:])\n",
    "    rects5 = plt.bar(index + 7*bar_width, perf[7][:], bar_width,alpha=opacity,color='#edf8a3',label=str_1[7][:])\n",
    "    rects5 = plt.bar(index + 8*bar_width, perf[8][:], bar_width,alpha=opacity,color='c',label=str_1[8][:])\n",
    "    rects5 = plt.bar(index + 9*bar_width, perf[9][:], bar_width,alpha=opacity,color='#fca55d',label=str_1[9][:])\n",
    "    rects5 = plt.bar(index + 10*bar_width, perf[10][:], bar_width,alpha=opacity,color='#e2514a',label=str_1[10][:])\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.xticks(index + bar_width,x)\n",
    "    plt.legend(loc='lower left',ncol=2)\n",
    "    plt.savefig(str(val)+'_'+str(tt)+'_'+'Graph.png', dpi = 1200)\n",
    "    plt.show(block=False)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_perf_evaluation_all(t):\n",
    "    # t = 0\n",
    "    Final_Feat, Final_Lab = main_load_org_data(t)  # t=1--Extract Again  0--load Stored\n",
    "    Sel_identifier_0, Sel_identifier_1, Sel_identifier_2, Sel_identifier_3 = main_find_Identifier_basef_FS(t,\n",
    "                                                                                                           Final_Feat,\n",
    "                                                                                                           Final_Lab)  # t=1--Extract Identifier Again  0--load Stored\n",
    "    #############Hybrid optimizer data balancing ##################################\n",
    "    Final_Feat_wo_bal = Final_Feat  #### Non Balanced Features\n",
    "    Final_Lab_wo_bal = Final_Lab  #### Non Balanced Labels\n",
    "    id = 6  # 0-No Balancing  1-Random Sampling   2-Pso based 3-GA based  4--SSA based  5--HHO Based  6---Proposed\n",
    "    Final_Feat, Final_Lab = main_output_all_Data_Balancing(t, id, Final_Feat, Final_Lab)\n",
    "    #########   Performance Evaluation  ######################################\n",
    "    Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,0)  ######  Comparitive  analysis varying training Percentage\n",
    "    # Final_Feat, Final_Lab, tst_data, tst_lab = main_data_splitup(Sel_identifier_3, Final_Feat, Final_Lab, 0.75)\n",
    "#     KF_Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,0)  ######  Comparitive  analysis varying K-Fold\n",
    "#     Prop_Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab,0)  ######  Performance analysis varying training Percentage\n",
    "#     Prop_KF_Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab, 0)  ######  Performance analysis varying K-Fold\n",
    "#     Prop_Identifier_Perf_Evaluation_save_all_final(Sel_identifier_0, Sel_identifier_1, Sel_identifier_2,Sel_identifier_3, Final_Feat, Final_Lab,0)  ######Attribute Selection Based Analysis\n",
    "#     Prop_Data_balancing_Perf_Evaluation_save_all_final(Sel_identifier_3, Final_Feat_wo_bal, Final_Lab_wo_bal,0)  ######  Data Balancing Based Analysis\n",
    "    Perf_Evaluation_RoC_AUC_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab, 0)  ######  Roc AUC  analysis\n",
    "    Perf_Evaluation_PRC_AUC_save_all_final(Sel_identifier_3, Final_Feat, Final_Lab, 0)  ######  PRC AUC  analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main_ext_data_all_1_prc(perf_A,perf_B,perf_C,perf_D,perf_E,perf_F,perf_G,perf_H,perf_I,perf_J,perf_K):\n",
    "    A = np.asarray(perf_A[:][:])\n",
    "    B = np.asarray(perf_B[:][:])\n",
    "    C = np.asarray(perf_C[:][:])\n",
    "    D = np.asarray(perf_D[:][:])\n",
    "    E = np.asarray(perf_E[:][:])\n",
    "    F = np.asarray(perf_F[:][:])\n",
    "    G = np.asarray(perf_G[:][:])\n",
    "    H = np.asarray(perf_H[:][:])\n",
    "    I = np.asarray(perf_I[:][:])\n",
    "    J = np.asarray(perf_J[:][:])\n",
    "    K = np.asarray(perf_K[:][:])\n",
    "    AA = A[:][:].transpose()\n",
    "    BB = B[:][:].transpose()\n",
    "    CC = C[:][:].transpose()\n",
    "    DD = D[:][:].transpose()\n",
    "    EE = E[:][:].transpose()\n",
    "    FF = F[:][:].transpose()\n",
    "    GG = G[:][:].transpose()\n",
    "    HH = H[:][:].transpose()\n",
    "    II = I[:][:].transpose()\n",
    "    JJ = J[:][:].transpose()\n",
    "    KK = K[:][:].transpose()\n",
    "    Perf_1, Perf_2, Perf_3,Perf_4,Perf_5=Main_perf_val_acc_sen_spe_1_prc(AA, BB, CC, DD, EE, FF, GG, HH, II, JJ, KK, 0)\n",
    "    # [Perf_1, Perf_2, Perf_3, Perf_4, Perf_5, Perf_6, Perf_7, Perf_8, Perf_9, Perf_10,Perf_11] = Main_perf_val_acc_sen_spe_1(AA, BB, CC, DD, EE, FF, GG, HH,,II,JJ,KK, tt)\n",
    "    Perf_1 = np.sort(Perf_1.transpose())[::-1].transpose()\n",
    "    Perf_2 = np.sort(Perf_2.transpose())[::-1].transpose()\n",
    "    Perf_3 = np.sort(Perf_3.transpose())[::-1].transpose()\n",
    "    Perf_4 = np.sort(Perf_4.transpose())[::-1].transpose()\n",
    "    Perf_5 = np.sort(Perf_5.transpose())[::-1].transpose()\n",
    "    # Perf_1 = np.sort(Perf_1.transpose())[::-1]\n",
    "    # Perf_1=Perf_1.transpose()\n",
    "    return Perf_1, Perf_2, Perf_3,Perf_4,Perf_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ext_data_all_1(perf_A,perf_B,perf_C,perf_D,perf_E,perf_F,perf_G,perf_H,perf_I,perf_J,perf_K):\n",
    "    A = np.asarray(perf_A[:][:])\n",
    "    B = np.asarray(perf_B[:][:])\n",
    "    C = np.asarray(perf_C[:][:])\n",
    "    D = np.asarray(perf_D[:][:])\n",
    "    E = np.asarray(perf_E[:][:])\n",
    "    F = np.asarray(perf_F[:][:])\n",
    "    G = np.asarray(perf_G[:][:])\n",
    "    H = np.asarray(perf_H[:][:])\n",
    "    I = np.asarray(perf_I[:][:])\n",
    "    J = np.asarray(perf_J[:][:])\n",
    "    K = np.asarray(perf_K[:][:])\n",
    "    AA = A[:][:].transpose()\n",
    "    BB = B[:][:].transpose()\n",
    "    CC = C[:][:].transpose()\n",
    "    DD = D[:][:].transpose()\n",
    "    EE = E[:][:].transpose()\n",
    "    FF = F[:][:].transpose()\n",
    "    GG = G[:][:].transpose()\n",
    "    HH = H[:][:].transpose()\n",
    "    II = I[:][:].transpose()\n",
    "    JJ = J[:][:].transpose()\n",
    "    KK = K[:][:].transpose()\n",
    "    Perf_1, Perf_2, Perf_3=Main_perf_val_acc_sen_spe_1(AA, BB, CC, DD, EE, FF, GG, HH, II, JJ, KK, 0)\n",
    "    # [Perf_1, Perf_2, Perf_3, Perf_4, Perf_5, Perf_6, Perf_7, Perf_8, Perf_9, Perf_10,Perf_11] = Main_perf_val_acc_sen_spe_1(AA, BB, CC, DD, EE, FF, GG, HH,,II,JJ,KK, tt)\n",
    "    return Perf_1, Perf_2, Perf_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ext_data_all_2(perf_A,perf_B,perf_C,perf_D,perf_E,perf_F,perf_G):\n",
    "    A = np.asarray(perf_A[:][:])\n",
    "    B = np.asarray(perf_B[:][:])\n",
    "    C = np.asarray(perf_C[:][:])\n",
    "    D = np.asarray(perf_D[:][:])\n",
    "    E = np.asarray(perf_E[:][:])\n",
    "    F = np.asarray(perf_F[:][:])\n",
    "    G = np.asarray(perf_G[:][:])\n",
    "\n",
    "    AA = A[:][:].transpose()\n",
    "    BB = B[:][:].transpose()\n",
    "    CC = C[:][:].transpose()\n",
    "    DD = D[:][:].transpose()\n",
    "    EE = E[:][:].transpose()\n",
    "    FF = F[:][:].transpose()\n",
    "    GG = G[:][:].transpose()\n",
    "\n",
    "    Perf_1, Perf_2, Perf_3=Main_perf_val_acc_sen_spe_2(AA, BB, CC, DD, EE, FF, GG, 0)\n",
    "    # [Perf_1, Perf_2, Perf_3, Perf_4, Perf_5, Perf_6, Perf_7, Perf_8, Perf_9, Perf_10,Perf_11] = Main_perf_val_acc_sen_spe_1(AA, BB, CC, DD, EE, FF, GG, HH,,II,JJ,KK, tt)\n",
    "    return Perf_1, Perf_2, Perf_3\n",
    "def main_ext_data_all_3(perf_A,perf_B,perf_C,perf_D,perf_E):\n",
    "    A = np.asarray(perf_A[:][:])\n",
    "    B = np.asarray(perf_B[:][:])\n",
    "    C = np.asarray(perf_C[:][:])\n",
    "    D = np.asarray(perf_D[:][:])\n",
    "    E = np.asarray(perf_E[:][:])\n",
    "\n",
    "\n",
    "    AA = A[:][:].transpose()\n",
    "    BB = B[:][:].transpose()\n",
    "    CC = C[:][:].transpose()\n",
    "    DD = D[:][:].transpose()\n",
    "    EE = E[:][:].transpose()\n",
    "\n",
    "\n",
    "    Perf_1, Perf_2, Perf_3=Main_perf_val_acc_sen_spe_3(AA, BB, CC, DD, EE, 0)\n",
    "    # [Perf_1, Perf_2, Perf_3, Perf_4, Perf_5, Perf_6, Perf_7, Perf_8, Perf_9, Perf_10,Perf_11] = Main_perf_val_acc_sen_spe_1(AA, BB, CC, DD, EE, FF, GG, HH,,II,JJ,KK, tt)\n",
    "    return Perf_1, Perf_2, Perf_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_ext_data_all_4(perf_A,perf_B,perf_C,perf_D):\n",
    "    A = np.asarray(perf_A[:][:])\n",
    "    B = np.asarray(perf_B[:][:])\n",
    "    C = np.asarray(perf_C[:][:])\n",
    "    D = np.asarray(perf_D[:][:])\n",
    "\n",
    "\n",
    "    AA = A[:][:].transpose()\n",
    "    BB = B[:][:].transpose()\n",
    "    CC = C[:][:].transpose()\n",
    "    DD = D[:][:].transpose()\n",
    "\n",
    "\n",
    "    Perf_1, Perf_2, Perf_3=Main_perf_val_acc_sen_spe_4(AA, BB, CC, DD, 0)\n",
    "    # [Perf_1, Perf_2, Perf_3, Perf_4, Perf_5, Perf_6, Perf_7, Perf_8, Perf_9, Perf_10,Perf_11] = Main_perf_val_acc_sen_spe_1(AA, BB, CC, DD, EE, FF, GG, HH,,II,JJ,KK, tt)\n",
    "    return Perf_1, Perf_2, Perf_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_perf_plot_all():\n",
    "    #########   Plot Final All  ######################################\n",
    "    for tt in range(7, 8):\n",
    "        if tt == 0:\n",
    "            perf_A = np.load('perf_A0.npy')\n",
    "            perf_B = np.load('perf_B0.npy')\n",
    "            perf_C = np.load('perf_C0.npy')\n",
    "            perf_D = np.load('perf_D0.npy')\n",
    "            perf_E = np.load('perf_E0.npy')\n",
    "            perf_F = np.load('perf_F0.npy')\n",
    "            perf_G = np.load('perf_G0.npy')\n",
    "            perf_H = np.load('perf_H0.npy')\n",
    "            perf_I = np.load('perf_I0.npy')\n",
    "            perf_J = np.load('perf_J0.npy')\n",
    "            perf_K = np.load('perf_K0.npy')\n",
    "            Perf_1, Perf_2, Perf_3=main_ext_data_all_1(perf_A, perf_B, perf_C, perf_D, perf_E, perf_F, perf_G, perf_H, perf_I, perf_J, perf_K)\n",
    "        elif tt == 1:\n",
    "            perf_A = np.load('KF_perf_A0.npy')\n",
    "            perf_B = np.load('KF_perf_B0.npy')\n",
    "            perf_C = np.load('KF_perf_C0.npy')\n",
    "            perf_D = np.load('KF_perf_D0.npy')\n",
    "            perf_E = np.load('KF_perf_E0.npy')\n",
    "            perf_F = np.load('KF_perf_F0.npy')\n",
    "            perf_G = np.load('KF_perf_G0.npy')\n",
    "            perf_H = np.load('KF_perf_H0.npy')\n",
    "            perf_I = np.load('KF_perf_I0.npy')\n",
    "            perf_J = np.load('KF_perf_J0.npy')\n",
    "            perf_K = np.load('KF_perf_K0.npy')\n",
    "            Perf_1, Perf_2, Perf_3=main_ext_data_all_1(perf_A, perf_B, perf_C, perf_D, perf_E, perf_F, perf_G, perf_H, perf_I, perf_J, perf_K)\n",
    "        elif tt == 2:\n",
    "            perf_A = np.load('Pro_perf_A0.npy')\n",
    "            perf_B = np.load('Pro_perf_B0.npy')\n",
    "            perf_C = np.load('Pro_perf_C0.npy')\n",
    "            perf_D = np.load('Pro_perf_D0.npy')\n",
    "            perf_E = np.load('Pro_perf_E0.npy')\n",
    "            Perf_1, Perf_2, Perf_3 = main_ext_data_all_3(perf_A, perf_B, perf_C, perf_D,perf_E)\n",
    "        elif tt == 3:\n",
    "            perf_A = np.load('Prop_KF_perf_A0.npy')\n",
    "            perf_B = np.load('Prop_KF_perf_B0.npy')\n",
    "            perf_C = np.load('Prop_KF_perf_C0.npy')\n",
    "            perf_D = np.load('Prop_KF_perf_D0.npy')\n",
    "            perf_E = np.load('Prop_KF_perf_E0.npy')\n",
    "            Perf_1, Perf_2, Perf_3 = main_ext_data_all_3(perf_A, perf_B, perf_C, perf_D,perf_E)\n",
    "        elif tt == 4:\n",
    "            perf_A = np.load('Identifier_perf_A0.npy')\n",
    "            perf_B = np.load('Identifier_perf_B0.npy')\n",
    "            perf_C = np.load('Identifier_perf_C0.npy')\n",
    "            perf_D = np.load('Identifier_perf_D0.npy')\n",
    "            Perf_1, Perf_2, Perf_3=main_ext_data_all_4(perf_A, perf_B, perf_C, perf_D)\n",
    "        elif tt == 5:\n",
    "            perf_A = np.load('Data_Bal_perf_A0.npy')\n",
    "            perf_B = np.load('Data_Bal_perf_B0.npy')\n",
    "            perf_C = np.load('Data_Bal_perf_C0.npy')\n",
    "            perf_D = np.load('Data_Bal_perf_D0.npy')\n",
    "            perf_E = np.load('Data_Bal_perf_E0.npy')\n",
    "            perf_F = np.load('Data_Bal_perf_F0.npy')\n",
    "            perf_G = np.load('Data_Bal_perf_G0.npy')\n",
    "            Perf_1, Perf_2, Perf_3=main_ext_data_all_2(perf_A, perf_B, perf_C, perf_D, perf_E, perf_F, perf_G)\n",
    "        elif tt == 6:\n",
    "            perf_A = np.load('ROC_AUC_perf_A0.npy')\n",
    "            perf_B = np.load('ROC_AUC_perf_B0.npy')\n",
    "            perf_C = np.load('ROC_AUC_perf_C0.npy')\n",
    "            perf_D = np.load('ROC_AUC_perf_D0.npy')\n",
    "            perf_E = np.load('ROC_AUC_perf_E0.npy')\n",
    "            perf_F = np.load('ROC_AUC_perf_F0.npy')\n",
    "            perf_G = np.load('ROC_AUC_perf_G0.npy')\n",
    "            perf_H = np.load('ROC_AUC_perf_H0.npy')\n",
    "            perf_I = np.load('ROC_AUC_perf_I0.npy')\n",
    "            perf_J = np.load('ROC_AUC_perf_J1.npy')\n",
    "            perf_K = np.load('ROC_AUC_perf_K1.npy')\n",
    "            Perf_A, Perf_2, Perf_3=main_ext_data_all_1(perf_A, perf_B, perf_C, perf_D, perf_E, perf_F, perf_G, perf_H, perf_I, perf_J, perf_K)\n",
    "            Perf_1 = np.zeros((11, 11))\n",
    "            Perf_1[:, 1:] = Perf_A[:,1:]\n",
    "            Perf_1[:, 0] = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "            Perf_1[:,-1]=[1,1,1,1,1,1,1,1,1,1,1]\n",
    "        else:\n",
    "            perf_A = np.load('ROC_AUC_perf_A0.npy')\n",
    "            perf_B = np.load('ROC_AUC_perf_B0.npy')\n",
    "            perf_C = np.load('ROC_AUC_perf_C0.npy')\n",
    "            perf_D = np.load('ROC_AUC_perf_D0.npy')\n",
    "            perf_E = np.load('ROC_AUC_perf_E0.npy')\n",
    "            perf_F = np.load('ROC_AUC_perf_F0.npy')\n",
    "            perf_G = np.load('ROC_AUC_perf_G0.npy')\n",
    "            perf_H = np.load('ROC_AUC_perf_H0.npy')\n",
    "            perf_I = np.load('ROC_AUC_perf_I0.npy')\n",
    "            perf_J = np.load('ROC_AUC_perf_J1.npy')\n",
    "            perf_K = np.load('ROC_AUC_perf_K1.npy')\n",
    "            Perf_1, Perf_2, Perf_3,Perf_4,Perf_5=main_ext_data_all_1_prc(perf_A, perf_B, perf_C, perf_D, perf_E, perf_F, perf_G, perf_H, perf_I, perf_J, perf_K)\n",
    "            Perf_1=ext_main_prc(Perf_1)\n",
    "            Perf_2=ext_main_prc(Perf_2)\n",
    "            Perf_3=ext_main_prc(Perf_3)\n",
    "            Perf_4=ext_main_prc(Perf_4)\n",
    "            Perf_5=ext_main_prc(Perf_5)\n",
    "        if tt==0:\n",
    "            x = np.asarray([40, 60, 80]).T\n",
    "            str_1 = ['SVM','SAE-LSTM','KNN','Hybridized CNN and Bi-LSTM','LightGBM','Adaboost','BiLSTM','PSO-BiLSTM','SSO-BiLSTM','HHO-BiLSTM',' Flabbergast - Hybrid Classifier']\n",
    "            Complete_Figure_11(x, Perf_1, 1, str_1, \"Training Percentage(%)\", \"Accuracy(%)\", tt)\n",
    "            Complete_Figure_11(x, Perf_2, 2, str_1, \"Training Percentage(%)\", \"Sensitivity(%)\", tt)\n",
    "            Complete_Figure_11(x, Perf_3, 3, str_1, \"Training Percentage(%)\", \"Specificity(%)\", tt)\n",
    "        elif tt==1:\n",
    "            x = np.asarray([6, 8, 10]).T\n",
    "            str_1 = ['SVM','SAE-LSTM','KNN','Hybridized CNN and Bi-LSTM','LightGBM','Adaboost','BiLSTM','PSO-BiLSTM','SSO-BiLSTM','HHO-BiLSTM',' Flabbergast - Hybrid Classifier']\n",
    "            Complete_Figure_11(x, Perf_1, 1, str_1, \"K-Fold\", \"Accuracy(%)\", tt)\n",
    "            Complete_Figure_11(x, Perf_2, 2, str_1, \"K-Fold\", \"Sensitivity(%)\", tt)\n",
    "            Complete_Figure_11(x, Perf_3, 3, str_1, \"K-Fold\", \"Specificity(%)\", tt)\n",
    "        elif tt==2:\n",
    "            x = np.asarray([40, 60, 80]).T\n",
    "            str_1 = ['Flabbergast-Hybrid Classifier with Population=10','Flabbergast-Hybrid Classifier with Population=20','Flabbergast-Hybrid Classifier with Population=30','Flabbergast-Hybrid Classifier with Population=40','Flabbergast-Hybrid Classifier with Population=50']\n",
    "            Complete_Figure_13(x, Perf_1, 1, str_1, \"Training Percentage(%)\", \"Accuracy(%)\", tt)\n",
    "            Complete_Figure_13(x, Perf_2, 2, str_1, \"Training Percentage(%)\", \"Sensitivity(%)\", tt)\n",
    "            Complete_Figure_13(x, Perf_3, 3, str_1, \"Training Percentage(%)\", \"Specificity(%)\", tt)\n",
    "        elif tt==3:\n",
    "            x = np.asarray([6, 8, 10]).T\n",
    "            str_1 = ['Flabbergast-Hybrid Classifier with Population=10','Flabbergast-Hybrid Classifier with Population=20','Flabbergast-Hybrid Classifier with Population=30','Flabbergast-Hybrid Classifier with Population=40','Flabbergast-Hybrid Classifier with Population=50']\n",
    "            Complete_Figure_13(x, Perf_1, 1, str_1, \"K-Fold\", \"Accuracy(%)\", tt)\n",
    "            Complete_Figure_13(x, Perf_2, 2, str_1, \"K-Fold\", \"Sensitivity(%)\", tt)\n",
    "            Complete_Figure_13(x, Perf_3, 3, str_1, \"K-Fold\", \"Specificity(%)\", tt)\n",
    "        elif tt==4:\n",
    "            x = np.asarray([40, 60, 80]).T\n",
    "            str_1 = ['GA based Selection','HHO based Selection','SSO based Selection','Flabbergast based Attribute Selection']\n",
    "            Complete_Figure_14(x, Perf_1, 1, str_1, \"Training Percentage(%)\", \"Accuracy(%)\", tt)\n",
    "            Complete_Figure_14(x, Perf_2, 2, str_1, \"Training Percentage(%)\", \"Sensitivity(%)\", tt)\n",
    "            Complete_Figure_14(x, Perf_3, 3, str_1, \"Training Percentage(%)\", \"Specificity(%)\", tt)\n",
    "        elif tt==5:\n",
    "            x = np.asarray([40, 60, 80]).T\n",
    "            str_1 = [\"No Balancing\",\"Random Oversampler\",\"PSO-SMOTE\",\"GA-SMOTE\",\"SSO-SMOTE\",\"HHO-SMOTE\",\"Flabbergast  SMOTE\"]\n",
    "            Complete_Figure_12(x, Perf_1, 1, str_1, \"Training Percentage(%)\", \"Accuracy(%)\", tt)\n",
    "            Complete_Figure_12(x, Perf_2, 2, str_1, \"Training Percentage(%)\", \"Sensitivity(%)\", tt)\n",
    "            Complete_Figure_12(x, Perf_3, 3, str_1, \"Training Percentage(%)\", \"Specificity(%)\", tt)\n",
    "        elif tt==6:\n",
    "            x = np.asarray([0,10,20,30,40,50,60,70,80,90,100]).T\n",
    "            str_1 = ['SVM','SAE-LSTM','KNN','Hybridized CNN and Bi-LSTM','LightGBM','Adaboost','BiLSTM','PSO-BiLSTM','SSO-BiLSTM','HHO-BiLSTM',' Flabbergast-Hybrid Classifier']\n",
    "            Complete_Figure_1(x, Perf_2,Perf_1, 1, str_1, \"FPR(%)\", \"TPR(%)\", tt)\n",
    "        else:\n",
    "            x = np.asarray([0,10,20,30,40,50,60,70,80,90,100]).T\n",
    "            str_1 = ['SVM','SAE-LSTM','KNN','Hybridized CNN and Bi-LSTM','LightGBM','Adaboost','BiLSTM','PSO-BiLSTM','SSO-BiLSTM','HHO-BiLSTM',' Flabbergast-Hybrid Classifier']\n",
    "            Complete_Figure_1(x, Perf_1,Perf_1, 1, str_1, \"Recall(%)\", \"Precision(%)\", tt)\n",
    "            Complete_Figure_1(x, Perf_2,Perf_2, 1, str_1, \"Recall(%)\", \"Precision(%)\", tt+1)\n",
    "            Complete_Figure_1(x, Perf_3,Perf_3, 1, str_1, \"Recall(%)\", \"Precision(%)\", tt+2)\n",
    "            Complete_Figure_1(x, Perf_4,Perf_4, 1, str_1, \"Recall(%)\", \"Precision(%)\", tt+3)\n",
    "            Complete_Figure_1(x, Perf_5,Perf_5, 1, str_1, \"Recall(%)\", \"Precision(%)\", tt+4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sub_functions import main_perf_evaluation_all,main_perf_plot_all\n",
    "#####################       Main Code           #############################\n",
    "import PySimpleGUI as sg\n",
    "VVV=sg.PopupYesNo('Do You want Complete Execution?')\n",
    "if (VVV == \"Yes\"):\n",
    "    t=0\n",
    "    main_perf_evaluation_all(t)\n",
    "    main_perf_plot_all()\n",
    "else:\n",
    "    main_perf_plot_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, activation='relu'), input_shape=(64,1)))\n",
    "model.add(Reshape((128, 1), input_shape=(128,)))\n",
    "model.add(MaxPooling1D(pool_size=(5)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "model.add(Dropout(0.06))\n",
    "model.add(Dense(6))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "#Create Flow Chart\n",
    "plot_model(model, to_file='chart/model_flowchart.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
